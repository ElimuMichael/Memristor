{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MemristorNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElimuMichael/Memristor/blob/master/Copy_of_MemristorNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rKorH1ZDVcvS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import h5py\n",
        "from time import perf_counter as my_timer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpmrqNgxSypz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ##Memristor NN Simulation\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Memristor Parameters\n",
        "Ron = 2000 #@param {type:\"integer\"}\n",
        "Roff = 2000000 #@param {type:\"integer\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "algRLBT1XHp4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conductanceValues(Ron, Roff):\n",
        "    '''\n",
        "    Calculates the conductance values from the resistance vaues provided\n",
        "    \n",
        "    Parameters:\n",
        "    -------------\n",
        "    \n",
        "    Ron: Integer value\n",
        "        \n",
        "        Usually 2000 for TiO2 memristors\n",
        "        The minimum resistance value of the memristor that when reached indicates that \n",
        "        the memristor is in a on state (1)\n",
        "        \n",
        "    Roff: Integer value \n",
        "        \n",
        "        Usually 2000000 for TiO2 memristors\n",
        "        The maximum resistance value of the memristor considered to be the value when reached, \n",
        "        the memristor is in off state (0)\n",
        "        \n",
        "    Returns:\n",
        "    ----------\n",
        "    conductance_values: a dictionary\n",
        "        \n",
        "        This containes the values of conductances calculated as a reciprocal of the resistances\n",
        "        \n",
        "        conductance_values[\"c_min\"]  ------------------ Minimum conductance(Reciprocal of maximum resistance)\n",
        "        conductance_values[\"c_max\"]  ------------------ Maximum conductance(Reciprocal of minimum resistance)\n",
        "        conductance_values[\"c_range\"]------------------ The difference between Minimum and Maximum conductance\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    Cmax, Cmin = (1/Ron, 1/Roff)\n",
        "    cond_range = Cmax - Cmin\n",
        "    \n",
        "    conductance_values = {\n",
        "        \"c_min\": Cmin,\n",
        "        \"c_max\": Cmax,\n",
        "        \"c_range\": cond_range\n",
        "    }\n",
        "    \n",
        "    return conductance_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNLZS7WbX21C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight_split(w_rows, w_cols, weight, mode='normal'):\n",
        "    \n",
        "    '''\n",
        "    Makes a weight split into positives and negatives grouped differently allow easy handling\n",
        "    Corresponding positive and negative weights are passed to the substractor to obtain the \n",
        "    total weight values onn the final memristor.\n",
        "    \n",
        "    Parameters:\n",
        "    -------------\n",
        "    w_rows: Integer value\n",
        "        \n",
        "        This is the number of row in the original weight\n",
        "        \n",
        "    W_cols: integer value\n",
        "        \n",
        "        This is the number of columns in the original weight. This is used to create two columns\n",
        "        to represent positive and negavite values of the memristor weights\n",
        "        \n",
        "    weight: numpy array or matrix\n",
        "        \n",
        "        This is a matrix of the weights from the weight file(pretrained weights)\n",
        "        \n",
        "    mode: can be normal or proposed\n",
        "        \n",
        "        normal: The weights be split as all postive values to the left and negative values\n",
        "                to the right\n",
        "        proposed: The weights be split in a 4X5 manner, each with two positive columns, followed by\n",
        "                two corresponding negative column weights and a redundant cell for overcoming the \n",
        "                defects\n",
        "                \n",
        "    Returns:\n",
        "    ----------\n",
        "    W: n-d array or matrix\n",
        "        \n",
        "        The splited weight values\n",
        "    \n",
        "    max_val: integer value\n",
        "        \n",
        "        The maximum absolute value in the weight matrix to be used in determining the conductance\n",
        "        split\n",
        "    \n",
        "    '''\n",
        "\n",
        "    # Obtain the absolute value of the stacked array\n",
        "    w_b = np.abs(weight)\n",
        "    \n",
        "    max_val = max(w_b.flatten())\n",
        "\n",
        "#     # Get the index of the maximum value\n",
        "#     max_index = w_b.argmax()\n",
        "\n",
        "#     # Retrieve the maximum value\n",
        "#     max_val = w_b.ravel()[max_index]\n",
        "\n",
        "    w_r, w_c = weight.shape\n",
        "\n",
        "    w_pos =np.zeros([w_r,w_cols]).reshape(w_r, w_cols)\n",
        "    w_neg = np.zeros([w_r,w_cols]).reshape(w_r, w_cols)\n",
        "\n",
        "    w_pos[weight > 0] = weight[weight > 0]\n",
        "    w_neg[weight <= 0] = weight[weight <= 0]*-1\n",
        "\n",
        "    W = np.hstack((w_pos, w_neg))\n",
        "    \n",
        "    if mode == 'proposed':\n",
        "        P = []\n",
        "        for i in range(0, w_c, 2):\n",
        "            if(i+1<w_c):\n",
        "                P.append(w_pos[:,i])\n",
        "                P.append(w_neg[:,i])\n",
        "                P.append(w_pos[:,i+1])\n",
        "                P.append(w_neg[:,i+1])\n",
        "           \n",
        "        W = np.array(P)\n",
        "        W = W.T\n",
        "        \n",
        "    # print(W)\n",
        "\n",
        "    # print(f\"Positive Weights\\n{W[:w_rows,:w_cols]}\\n\")\n",
        "    # print(f\"Negative Weights\\n{W[:w_rows,w_cols:]}\")\n",
        "    # print(f\"Positive Bias\\n{W[w_rows:,:w_cols]}\\n\")\n",
        "    # print(f\"Negative Bias\\n{W[w_rows:,w_cols:]}\")\n",
        "    # assert w_pos.shape == w_b_T.shape\n",
        "    \n",
        "    return W, max_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VaxIJ36rX9SV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight_bias_cond(w, conductance_values, w_b_max):\n",
        "    \n",
        "    '''\n",
        "    Convert the weights so as to be represented as conductance values\n",
        "    The output weights will be conductance values as a representative of  the existing weights\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    w: an array or matrix of weight values\n",
        "    \n",
        "        The weights that we need to convert to conductance values\n",
        "        \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "    \n",
        "        Contains the calculated conductance values and range\n",
        "        c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "        c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "        cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "        \n",
        "    max_val: float or double\n",
        "        The maximum absolute value in the weight matrix to be used in determining the conductance\n",
        "        split\n",
        "        \n",
        "    Returns:\n",
        "    ----------\n",
        "    w_cond: n-d array or matrix\n",
        "        \n",
        "        Weight values converted as conductances of the memristor\n",
        "        These weight values have to be in within the range of the conductance values\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Extract Conductance Values\n",
        "    cond_range = conductance_values[\"c_range\"]\n",
        "    Cmin = conductance_values[\"c_min\"]\n",
        "    Cmax = conductance_values[\"c_max\"]\n",
        "    \n",
        "    w_cond = (w/w_b_max)*cond_range + Cmin\n",
        "    \n",
        "    return w_cond"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "edngem02YR4L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_con_weights(weighted_bits, cond_split):\n",
        "    \n",
        "    # Move the weight values to the conductance levels\n",
        "    r, c = weighted_bits.shape\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            for k in range(len(cond_split)):\n",
        "                weighted_bits[i, j] = cond_split[np.argmax(cond_split>=weighted_bits[i, j] )]\n",
        "                \n",
        "#     for con_val in cond_split:\n",
        "#         if weighted_bits < con_val:\n",
        "#             weighted_bits = con_val\n",
        "#             break    \n",
        "    \n",
        "    return weighted_bits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ppw89yhYZhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_red_array(w, per_def, conductance_values, mode, filter_window):\n",
        "    \n",
        "    '''\n",
        "    A function to add redundat rows and columns to the existing crossbar array\n",
        "    These columns are used for overcoming the faults that may exist on the memristor.\n",
        "    The rows and columns are dynamic and entirely based on the percentage defect to minimize memory wastage\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    w: an n-d array of conductance weight values\n",
        "    \n",
        "        The crossbar array with weighted conductance values\n",
        "        We add redundant rows and columns to helf overcome the existing faults\n",
        "    \n",
        "    perc_def: an integer\n",
        "    \n",
        "        This number indicates the percentage of the faults on the memristor device.\n",
        "        It is used in dynamically calculating the required redundant rows and columns for the defected memristor\n",
        "        \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "    \n",
        "        Contains the calculated conductance values and range\n",
        "        c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "        c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "        cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "        \n",
        "    mode: can be normal or proposed\n",
        "        \n",
        "        normal: The weights be split as all postive values to the left and negative values\n",
        "                to the right\n",
        "        proposed: The weights be split in a 4X5 manner, each with two positive columns, followed by\n",
        "                two corresponding negative column weights and a redundant cell for overcoming the \n",
        "                defects\n",
        "        \n",
        "    Returns:\n",
        "    ----------\n",
        "    \n",
        "    crossbar: n-d array or matrix\n",
        "        \n",
        "        A matrix of weights with redundant rows and columns depending on the fault percentage\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Get the minimum conductance from the conductance values\n",
        "    cond_min = conductance_values['c_min']\n",
        "    \n",
        "    # Expand the array to include fault tolerant cells\n",
        "    w_row, w_col = w.shape\n",
        "    cols = 0\n",
        "    \n",
        "    # Percentage of rows and columns to add\n",
        "    rows = int(np.ceil((per_def/100)*w_row))\n",
        "    \n",
        "    if mode =='normal':\n",
        "        cols = int(np.ceil((per_def/100)*w_col))\n",
        "\n",
        "        if cols%2 != 0:\n",
        "            cols = cols+1\n",
        "    \n",
        "        red_cols = np.zeros((w_row, cols))+cond_min\n",
        "\n",
        "        w2 = np.concatenate((w, red_cols), axis=1)\n",
        "\n",
        "        red_rows = np.zeros((rows, w2.shape[1]))+cond_min\n",
        "\n",
        "        crossbar = np.concatenate((w2, red_rows), axis=0)\n",
        "    \n",
        "    if mode == 'proposed':\n",
        "        P = []\n",
        "        red_cols = np.zeros((w_row, 1))+cond_min\n",
        "        \n",
        "        for j in np.arange(0, w_col, 1):\n",
        "            if j%filter_window == 0 and j !=0:\n",
        "                # Append a redundant column after the first set of positive and negative cells\n",
        "                P.append(red_cols[:, 0])\n",
        "                P.append(red_cols[:, 0])\n",
        "                # Append the next set of weights after the redundant column\n",
        "                P.append(w[:, j])\n",
        "            else:\n",
        "                # Apply the normal set of weights to the crossbar\n",
        "                P.append(w[:, j])\n",
        "        # Append a redundant column to the last set of column cells\n",
        "        P.append(red_cols[:, 0])\n",
        "        P.append(red_cols[:, 0])\n",
        "        \n",
        "        P = np.array(P)\n",
        "        crossbar = P.T\n",
        "        \n",
        "        # print(\"crossbar:\\n\",crossbar)\n",
        "\n",
        "    return crossbar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fWLo6WG5Yd8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def groupings(cells, filter_size=4):\n",
        "    \n",
        "    '''\n",
        "    Takes in the existing cells and modifies their arrangments\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    cells: list of cells\n",
        "    \n",
        "        list containing all the crossbar cells arranged in order\n",
        "        \n",
        "    Returns:\n",
        "    ---------\n",
        "    crossbar_split: dictionary\n",
        "    \n",
        "        Outputs a dictionary containing the crossbar split into the positive, negative,\n",
        "        redundant and grouping of the cells that need to be handled together\n",
        "        \n",
        "        crossbar_split['positive']  ................. Positive Crossbar Cells \n",
        "        crossbar_split['negative']  ................. Negative Crossbar Cells\n",
        "        crossbar_split['redundant'] ................. Redundant Columns\n",
        "        crossbar_split['groups']    ................. Crossbar Cell groups\n",
        "    \n",
        "    '''\n",
        "    step = 0\n",
        "    xbr_pos = []\n",
        "    xbr_neg = []\n",
        "    xbr_red_pos = []\n",
        "    xbr_red_neg = []\n",
        "    groups = []\n",
        "    filter_size\n",
        "    for i in cells:\n",
        "        if i[1]%6 == 0:\n",
        "            # groups.append([i, (i[0], i[1]+2), (i[0], i[1]+1), (i[0], i[1]+3), (i[0], i[1]+split_factor)])\n",
        "            groups.append([i, (i[0], i[1]+1), (i[0], i[1]+filter_size), (i[0], i[1]+filter_size + 1)])\n",
        "            groups.append([(i[0], i[1]+2), (i[0], i[1]+3), (i[0], i[1]+filter_size),(i[0], i[1]+filter_size + 1)])\n",
        "            xbr_pos.append(i)\n",
        "            xbr_neg.append((i[0], i[1]+1))\n",
        "            xbr_pos.append((i[0], i[1]+2))\n",
        "            xbr_neg.append((i[0], i[1]+3))\n",
        "            xbr_red_pos.append((i[0], i[1]+filter_size))\n",
        "            xbr_red_neg.append((i[0], i[1]+filter_size + 1))\n",
        "            \n",
        "    crossbar_split = {\n",
        "        \"positive\":xbr_pos,\n",
        "        \"negative\":xbr_neg,\n",
        "        \"redundant_pos\":xbr_red_pos,\n",
        "        \"redundant_neg\":xbr_red_neg,\n",
        "        \"groups\":groups\n",
        "    }\n",
        "            \n",
        "    return crossbar_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N1PSWnFYiMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_defects(norm_weight, cxbar, perc_def, conductance_values, mode=\"normal\", mask=4, case='crossbar_with_split', seed_val=0):\n",
        "    \n",
        "    '''\n",
        "    Adds defects to an existing memristor crossbar array. The distribution of the defects varies.\n",
        "    A random pick of the required number od cells is picked based on the percentage defect\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    cxbar: an array of conductance weight values\n",
        "    \n",
        "        The original crossbar array with weighted conductance values\n",
        "    \n",
        "    perc_def: an integer\n",
        "    \n",
        "        This number indicates the percentage of the faults on the memristor device.\n",
        "        It is used in dynamically calculating the required redundant rows and columns for the defected memristor\n",
        "        \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "    \n",
        "        Contains the calculated conductance values and range\n",
        "        c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "        c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "        cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "        \n",
        "    Returns:\n",
        "    ----------\n",
        "    \n",
        "    defects: dictionary\n",
        "        A dictionary containing the generated faulty crossbar, the different faulty and none faulty cells\n",
        "        \n",
        "        defects['xbar']       .............. Generated Faulty crossbar\n",
        "        defects['all_cells']  .............. All Cells\n",
        "        defects['f_cells']    .............. Faulty Cells\n",
        "        defects['SA_0']       .............. Stuck at 0 Cells\n",
        "        defects['SA_1']       .............. Stuck at 1 Cells\n",
        "    \n",
        "    '''\n",
        "    defected = {}\n",
        "    \n",
        "    f_xbar = np.array(cxbar)\n",
        "    xbar = []\n",
        "    r, c = cxbar.shape\n",
        "    \n",
        "    r_norm, c_norm = norm_weight.shape\n",
        "    all_cells = []\n",
        "    all_cells_norm = []\n",
        "    global cells_to_pick\n",
        "    \n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            all_cells.append((i, j))\n",
        "            \n",
        "    for i in range(r_norm):\n",
        "        for j in range(c_norm):\n",
        "            all_cells_norm.append((i, j))\n",
        "            \n",
        "            \n",
        "    # TWO CASES CONSIDERED IN THIS IMPLEMENTATION\n",
        "    # Considering that each split can be faulty, and picking up the likely faulty cells\n",
        "    # Use the fault on the general crossbar and get the number of likely affected cells\n",
        "    # Choose the number of cells from the likely faulty cells\n",
        "\n",
        "    SA_0 = []\n",
        "    SA_1 = []\n",
        "    defected = {}\n",
        "    pad = 0;\n",
        "    h_stride = mask\n",
        "    w_stride = mask + 2\n",
        "\n",
        "    if perc_def > 0:\n",
        "\n",
        "        np.random.seed(seed_val)\n",
        "        faulty_sample =[]\n",
        "        faulty_cells = []\n",
        "\n",
        "        n_H = int(np.ceil((r - h_stride + 2*pad)/h_stride) + 1)\n",
        "        n_W = int(np.ceil((c - w_stride + 2*pad)/w_stride) + 1)\n",
        "\n",
        "        for h in range(n_H):            # Loop over the vertical axis\n",
        "            for w in range(n_W):        # Loop over the horizontal axis\n",
        "                vert_start = h*h_stride\n",
        "                v_end = vert_start + h_stride\n",
        "                if v_end >= r:\n",
        "                    vert_end = r\n",
        "                else:\n",
        "                    vert_end = v_end\n",
        "\n",
        "                horiz_start = w*w_stride\n",
        "                h_end = horiz_start + w_stride\n",
        "\n",
        "                if h_end >= c:\n",
        "                    horiz_end = c\n",
        "                else:\n",
        "                    horiz_end = h_end\n",
        "\n",
        "                # Use the corners to define the 3D slice of Weight Matrix\n",
        "                a_slice_prev = f_xbar[vert_start:vert_end, horiz_start:horiz_end]\n",
        "\n",
        "                # print(\"Slice h{} w{}\\n {}\\n\".format(h, w, a_slice_prev))\n",
        "\n",
        "                cell = []\n",
        "                for y in range(horiz_start, horiz_end):\n",
        "\n",
        "                    for x in range(vert_start, vert_end):\n",
        "                        cell.append((x, y))\n",
        "                    # Apply the faults using the filter - Convolution Manner\n",
        "                    # print(\"h_stride*w_stride: \", h_stride*w_stride)\n",
        "                    # print(\"cell:\\n\",cell)\n",
        "                    # Randomly Pick out cells from a random selection pattern\n",
        "                    cell_choosing = np.random.permutation(cell)  \n",
        "                    # my_cells = set(cells)\n",
        "                    # Find out the number of cells to change according to the defect percentage\n",
        "                    cells_to_change = int(np.ceil((perc_def/100)*(h_stride*w_stride)))\n",
        "                    # print(\"cell_choosing:\\n\",cells_to_change)\n",
        "                    # Choose from the random picks\n",
        "                    # faulty_cells = faulty_chosen(cell_choosing, cells_to_change)\n",
        "                    faulty_cells = faulty_chosen(norm_weight, cell_choosing, cells_to_change)\n",
        "\n",
        "                faulty_sample.append(faulty_cells)\n",
        "\n",
        "        likely_faulty = cell_list(faulty_sample)\n",
        "        # print(\"likely_faulty:\\n\",likely_faulty)\n",
        "\n",
        "        # Permute all the cells that have been chosen\n",
        "        permuted = np.random.permutation(likely_faulty)\n",
        "\n",
        "        # Three case Scenario:\n",
        "        # Considering the fault to be distributed in the entire crossbar with split\n",
        "        \n",
        "        # Defined by the number of cells in the crossbar excluding the proposed crossbar arrangement\n",
        "        cells_to_pick = int(np.ceil((perc_def/100)*(r_norm*c_norm)))\n",
        "        cells_considered = [] \n",
        "        \n",
        "        if case == 'crossbar_no_split':               \n",
        "            permuted = np.random.permutation(all_cells)\n",
        "\n",
        "        # Pick the cells\n",
        "        cells_considered = faulty_chosen(norm_weight, permuted, cells_to_pick)\n",
        "\n",
        "        # print(\"permuted:\\n\",permuted)\n",
        "        \n",
        "        if mode=='normal':\n",
        "            f_xbar = np.array(norm_weight)\n",
        "            defected = distribute_fault(cells_considered, conductance_values, f_xbar, norm_weight, all_cells_norm, mode)\n",
        "    \n",
        "        elif mode=='proposed':\n",
        "            defected = distribute_fault(cells_considered, conductance_values, f_xbar, norm_weight, all_cells, mode)\n",
        "        \n",
        "        \n",
        "    # No Fault\n",
        "    else:\n",
        "        if mode=='normal':\n",
        "            f_xbar = np.array(norm_weight)\n",
        "            all_cells = all_cells_norm\n",
        "        \n",
        "        defected = {\n",
        "        \"xbar\":f_xbar,\n",
        "        \"all_cells\":all_cells,\n",
        "        \"f_cells\":[],\n",
        "        \"SA_0\": [],\n",
        "        \"SA_1\":[] \n",
        "        }\n",
        "        # if perc_def == 0:\n",
        "            # print(f'Fault Distribution\\n{\"#\"*40}\\nSA1 - Fault: {perc_def}%\\nSA0 - Fault: {perc_def}%\\n')\n",
        "        # else:\n",
        "            # print(f'Fault Distribution\\n{\"#\"*40}\\nSA1 - Fault: {(len(SA1)/ len(faulty_cells))*100}%\\nSA0 - Fault: {(len(SA0)/ len(faulty_cells))*100}%\\n')\n",
        "    \n",
        "    return defected\n",
        "\n",
        "def faulty_chosen(or_xbar, choosen_cells, cells_number):\n",
        "    \n",
        "    # print(\"choosen_cells: \",choosen_cells)\n",
        "    # print(\"cells_number: \",cells_number)\n",
        "    r, c = or_xbar.shape\n",
        "    cells = []\n",
        "    \n",
        "    for cell in choosen_cells:\n",
        "        cells.append(tuple(cell))\n",
        "    \n",
        "    f_cells = []    \n",
        "    \n",
        "    # Check if there are any faulty Cells\n",
        "    if len(cells) > 1:\n",
        "        for i in range(len(cells)):\n",
        "            if len(f_cells) < cells_number:\n",
        "                if cells[i][0] < r and cells[i][1]<c:\n",
        "                    f_cells.append((cells[i][0],cells[i][1]))\n",
        "            else:\n",
        "                break\n",
        "    else:\n",
        "        # Convert none list cells to form a tupple\n",
        "        for cell in cells:\n",
        "            if type(cell) == list:\n",
        "                if cell[0] < r and cell[1]<c:\n",
        "                    f_cells.append((cell[0],cell[1]))\n",
        "            else:\n",
        "                if cell[0] < r and cell[1]<c:\n",
        "                    f_cells.append(cell)\n",
        "    \n",
        "    return f_cells\n",
        "\n",
        "def cell_list(cells):\n",
        "    \n",
        "    perm_cells = []\n",
        "                    \n",
        "    for i in cells:\n",
        "        for j in i:\n",
        "            perm_cells.append(j)\n",
        "            \n",
        "    return perm_cells\n",
        "\n",
        "def distribute_fault(faulty_cells, conductance_values, f_xbar, cxbar, all_cells, mode):\n",
        "    distribution = {}\n",
        "    r, c = cxbar.shape\n",
        "    # Extract Conductance Values\n",
        "    c_min = conductance_values[\"c_min\"]\n",
        "    c_max = conductance_values[\"c_max\"]\n",
        "    # Fault Distribution\n",
        "    SA0 = []\n",
        "    SA1 = []\n",
        "    \n",
        "    N = len(faulty_cells)\n",
        "    if N > 0:\n",
        "        for i in range(N):\n",
        "            if i < N//2:\n",
        "                f_xbar[faulty_cells[i][0],faulty_cells[i][1]] = c_min\n",
        "                SA0.append((faulty_cells[i][0],faulty_cells[i][1]))\n",
        "                \n",
        "            else:\n",
        "                f_xbar[faulty_cells[i][0],faulty_cells[i][1]] = c_max\n",
        "                SA1.append((faulty_cells[i][0],faulty_cells[i][1]))\n",
        "    else:\n",
        "        f_xbar = cxbar\n",
        "    \n",
        "    distribution = {\n",
        "        \"xbar\":f_xbar,\n",
        "        \"all_cells\":all_cells,\n",
        "        \"f_cells\":faulty_cells,\n",
        "        \"SA_0\": SA0,\n",
        "        \"SA_1\":SA1 \n",
        "    }\n",
        "    return distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UexhRvtXYm6Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xbr_visualization(defects, or_xbar_cols, or_xbar_rows, c_min, mod_pos, mod_neg, mode):\n",
        "    \n",
        "    '''\n",
        "    Visualize the crossbar array with or without defects for every leyer\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    defects:dictionary\n",
        "    \n",
        "        This contains the faulty crossbars, the cells with specific faults\n",
        "        defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "        defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "        defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "        \n",
        "    or_xbar_cols: integer value\n",
        "        \n",
        "        The number of columns in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    or_xbar_rows: integer value\n",
        "        \n",
        "        The number of rows in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    c_min: float or double\n",
        "        \n",
        "        The minimum conductance value of the memristor\n",
        "    \n",
        "    mod_pos: an array\n",
        "    \n",
        "        Array containing all memristor cells considered to be on the positive side of the crossbar\n",
        "    \n",
        "    mod_neg: an array\n",
        "    \n",
        "        Array containing all memristor cells considered to be on the negative side of the crossbar\n",
        "    \n",
        "        \n",
        "    mode: can be normal or proposed\n",
        "        \n",
        "        normal: The weights be split as all postive values to the left and negative values\n",
        "                to the right\n",
        "        proposed: The weights be split in a 4X5 manner, each with two positive columns, followed by\n",
        "                two corresponding negative column weights and a redundant cell for overcoming the \n",
        "                defects\n",
        "        \n",
        "     Returns:\n",
        "    ----------\n",
        "    Returns a plot of the graph containing the memristor cells\n",
        "    Those in red are fault cells\n",
        "    Those in green are the postive cells\n",
        "    Those in green are the negative cells\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Extract Features from a defected crossbar\n",
        "    xbar = defects['xbar']\n",
        "    aff_cells = defects['f_cells']\n",
        "    all_xbar_cells = defects['all_cells']\n",
        "    sa0 = defects['SA_0']\n",
        "    sa1 = defects['SA_1']\n",
        "    \n",
        "    r, c = xbar.shape\n",
        "    # print(f'rows = {r}\\nColumns = {c}')\n",
        "    \n",
        "    xbar_cells = np.array(all_xbar_cells)\n",
        "    faulty_ones = np.array(aff_cells)\n",
        "    \n",
        "    \n",
        "    # Distinguish positive and Negative crossbars\n",
        "    pos_xbr = []\n",
        "    rec = []\n",
        "    neg_xbr = []\n",
        "    for x in all_xbar_cells:\n",
        "        if xbar[x] == c_min:\n",
        "            rec.append(x)\n",
        "            \n",
        "        if x[1] < or_xbar_cols and x[0]<or_xbar_rows:\n",
        "            pos_xbr.append(np.array(x))\n",
        "\n",
        "        if or_xbar_cols <= x[1] < (or_xbar_cols*2) and x[0]<or_xbar_rows:\n",
        "            neg_xbr.append(np.array(x))    \n",
        " \n",
        "    if mode == 'normal':\n",
        "        pos__xbr = np.array(pos_xbr)\n",
        "        neg__xbr = np.array(neg_xbr)\n",
        "    \n",
        "    if mode == 'proposed':\n",
        "        pos__xbr = np.array(mod_pos)\n",
        "        neg__xbr = np.array(mod_neg)\n",
        "        \n",
        "    rec = np.array(rec)\n",
        "    \n",
        "    # Demacate SA0 and SA1 Faults\n",
        "    SA0 = np.array(sa0)\n",
        "    SA1 = np.array(sa1)\n",
        "    \n",
        "    plt.style.use('dark_background')\n",
        "    plt.figure(figsize=(50, 20))\n",
        "    \n",
        "    mpl.rcParams['grid.color'] = 'brown'\n",
        "    mpl.rcParams['grid.linestyle'] = 'solid'\n",
        "    mpl.rcParams['grid.linewidth'] = 0.5\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.scatter(xbar_cells[:,1], xbar_cells[:,0],s = 20, marker='s',c='white', label='Redundant cells' )\n",
        "    \n",
        "    plt.scatter(pos__xbr[:,1], pos__xbr[:,0],s = 20, c='green', marker= 's', label='Positive Weight cells' )\n",
        "    plt.scatter(neg__xbr[:,1], neg__xbr[:,0],s = 20,c='blue', marker= 's', label='Negative Weight cells' )\n",
        "    plt.scatter(rec[:,1], rec[:,0],s = 20, c='white', marker= 's', label='Available for recovery')\n",
        "#     plt.scatter(faulty_ones[:,1],faulty_ones[:,0], c='red', marker='o')\n",
        "    if SA0.size > 0:\n",
        "        plt.scatter(SA0[:,1],SA0[:,0],s = 20, c='red', marker='s', label='SA0 Weight cells')\n",
        "    if SA1.size > 0:\n",
        "        plt.scatter(SA1[:,1],SA1[:,0],s = 20, c='yellow', marker='s', label='SA1 Weight cells')\n",
        "    \n",
        "    \n",
        "    # plt.scatter(usable_cells[:,1], usable_cells[:,0],s = 20, marker= 's', label='Usable cells' )\n",
        "    \n",
        "    plt.ylim(r,-1)\n",
        "    plt.xlim(-1,c)\n",
        "    \n",
        "    plt.legend(loc=9, bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
        "    \n",
        "    return plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yAI3y9bYsgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def corr_rows_cols(xbr, defects, c, conductance_values):\n",
        "    \n",
        "    '''\n",
        "    This process uses the existing cells without the need for the redundant rows and columns\n",
        "    to overcome the faults in the memristor\n",
        "    \n",
        "    Parameters:\n",
        "    ------------\n",
        "    xbr: matrix or numpy array\n",
        "    \n",
        "        This is the crossbar array with additional redundant columns without defects added. \n",
        "        It is used for comparison purposes to help find the original values of the affected cells\n",
        "        \n",
        "    defects:dictionary\n",
        "    \n",
        "        This contains the faulty crossbars, the cells with specific faults\n",
        "        defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "        defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "        defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "    \n",
        "    c: integer value\n",
        "    \n",
        "        The number of columns in the original weight without split to help determine where positive\n",
        "        and negative values are seperated.\n",
        "    \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "            \n",
        "        Contains the calculated conductance values and range\n",
        "\n",
        "        c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "        c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "        cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "            \n",
        "    Return:\n",
        "    ---------\n",
        "        \n",
        "    xbr_f:matrix or numpy array\n",
        "        The finally rectified crossbar\n",
        "    \n",
        "    need_rc:array\n",
        "        This is an array containing the cells that require redundant columns to overcome the faults\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    # Extract conductance Values\n",
        "    c_min = conductance_values[\"c_min\"]\n",
        "    c_max = conductance_values[\"c_max\"]\n",
        "    \n",
        "    # Extract the defects\n",
        "    xbr_f = defects['xbar']\n",
        "    SA0 = defects['SA_0']\n",
        "    SA1 = defects['SA_1']\n",
        "    \n",
        "    SA = SA0 + SA1\n",
        "    need_rc = []\n",
        "    rc = []\n",
        "    \n",
        "    for i in SA:\n",
        "        # SA0 FAULT HANDLING CRITERIA\n",
        "        if xbr_f[i]==c_min:\n",
        "            if i[1] < c:\n",
        "                if xbr[i] != c_min:\n",
        "                    if (i[0], i[1]+c) not in SA:\n",
        "                        xbr_f[i[0],i[1]+c] = c_min\n",
        "            \n",
        "            if c<=i[1] < c*2:\n",
        "                if xbr[i] != c_min:\n",
        "                    if (i[0], i[1]-c) not in SA:\n",
        "                        xbr_f[i[0],i[1]-c] = c_min\n",
        "\n",
        "        # SA1 FAULT HANDLING CRITERIA\n",
        "        if xbr_f[i] == c_max:\n",
        "            if i[1]<c:\n",
        "                if xbr[i] > c_min:\n",
        "                    if (i[0], i[1]+c) not in SA:\n",
        "                        \n",
        "                        if xbr_f[(i[0], i[1]+c)] < c_max - xbr[i] + c_min:\n",
        "                            \n",
        "                            xbr_f[(i[0], i[1]+c)] = c_max - xbr[i] + c_min\n",
        "                \n",
        "            if c<=i[1]<c*2:\n",
        "                if xbr[i] > c_min:\n",
        "                    if (i[0], i[1]-c) not in SA:\n",
        "                        \n",
        "                        if xbr_f[(i[0], i[1]-c)] < c_max - xbr[i] + c_min:\n",
        "                        \n",
        "                            xbr_f[(i[0], i[1]-c)] = c_max - xbr[i] + c_min\n",
        "    \n",
        "    return xbr_f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTBf1uR6ZS5o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def red_rows_cols(xbr, defects, c, conductance_values, seed_val=0):\n",
        "    \n",
        "    '''\n",
        "    This process uses the approach of both redundant columns and the existing cells which\n",
        "    is an approach tending to use the advantges of both methods while taking advantage of the\n",
        "    pitfalls of the other method\n",
        "    \n",
        "    Parameters:\n",
        "    ------------\n",
        "    xbr: matrix or numpy array\n",
        "    \n",
        "        This is the crossbar array with additional redundant columns without defects added. \n",
        "        It is used for comparison purposes to help find the original values of the affected cells\n",
        "        \n",
        "    defects:dictionary\n",
        "    \n",
        "        This contains the faulty crossbars, the cells with specific faults\n",
        "        defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "        defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "        defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "    \n",
        "    c: integer value\n",
        "    \n",
        "        The number of columns in the original weight without split to help determine where positive\n",
        "        and negative values are seperated.\n",
        "    \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "            \n",
        "        Contains the calculated conductance values and range\n",
        "\n",
        "        c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "        c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "        cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "            \n",
        "    Return:\n",
        "    ---------\n",
        "        \n",
        "    xbr_f:matrix or numpy array\n",
        "        The finally rectified crossbar\n",
        "    \n",
        "    mapping:array\n",
        "        This is an array containing the cells and their corresponding redundant columns used in overcoming\n",
        "        the fault\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    # Extract conductance Values\n",
        "    c_min = conductance_values[\"c_min\"]\n",
        "    c_max = conductance_values[\"c_max\"]\n",
        "    \n",
        "    # Extract the defects\n",
        "    xbr_f = defects['xbar']\n",
        "    SA_0 = defects['SA_0']\n",
        "    SA_1 = defects['SA_1']\n",
        "    \n",
        "    SA = SA_0 + SA_1\n",
        "    xbr_cols = xbr_f.shape[1]\n",
        "    xbr_or = xbr.shape[1]\n",
        "    red_cols = xbr_cols - c*2\n",
        "    red_pos = int(red_cols/2)\n",
        "    mappings = []\n",
        "    r_c_rec = []\n",
        "    r_c = 0\n",
        "    \n",
        "    if red_pos!=0:\n",
        "        for i in SA:\n",
        "            \n",
        "            np.random.seed(seed_val)\n",
        "\n",
        "            # SA0 FAULT HANDLING CRITERIA\n",
        "            if xbr_f[i]==c_min:\n",
        "                if i[1] < c:\n",
        "                    if xbr[i] > c_min:\n",
        "                        r_c = random.choice(np.arange(red_pos))\n",
        "                        # Corresponding negative cell not faulty or SA_0\n",
        "                        if(i[0], i[1]+c) not in SA or (i[0], i[1]+c) in SA_0:\n",
        "                            \n",
        "                            # Recovery Positive Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c+red_pos) not in SA or (i[0], c*2+r_c+red_pos) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                    xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Positive Cell not faulty, Recovery Negative Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c+red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Positive Cell Faulty-SA_1, Recovery Negative Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c+red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c+red_pos] < c_max - xbr[i] + c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c+red_pos] = c_max - xbr[i] + c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                        \n",
        "                        # Corresponding negative cell SA_1\n",
        "                        if(i[0], i[1]+c) in SA_1:\n",
        "                            \n",
        "                            # Recovery Positive Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Stuck At Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "\n",
        "\n",
        "                if c<=i[1] < c*2:\n",
        "                    if xbr[i] > c_min:\n",
        "                        r_c = random.choice(range(red_pos, red_cols))\n",
        "                        \n",
        "                        # Corresponding Positive cell not faulty or SA_0\n",
        "                        if(i[0], i[1]-c) not in SA or (i[0], i[1]-c) in SA_0:\n",
        "                            \n",
        "                            # Recovery Negative Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) not in SA or (i[0], c*2+r_c-red_pos) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                    xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell not faulty, Recovery Positive Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell Faulty-SA_1, Recovery Positive Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c-red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c-red_pos] < c_max - xbr[i] + c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c-red_pos] = c_max - xbr[i] + c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                                    \n",
        "                        # Corresponding Positive cell SA_1\n",
        "                        if(i[0], i[1]-c) in SA_1:\n",
        "                            \n",
        "                            # Recovery Negative Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) not in SA or (i[0], c*2+r_c-red_pos) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell not faulty, Recovery Positive Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell Faulty-SA_1, Recovery Positive Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c-red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c-red_pos] > c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c-red_pos] = c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "\n",
        "            # SA1 FAULT HANDLING CRITERIA\n",
        "            if xbr_f[i] == c_max:\n",
        "                if i[1] < c:\n",
        "                    if xbr[i] > c_min:\n",
        "                        r_c = random.choice(np.arange(red_pos))\n",
        "                        # Corresponding negative cell not faulty or SA_0\n",
        "                        if(i[0], i[1]+c) not in SA or (i[0], i[1]+c) in SA_0:\n",
        "                            \n",
        "                            # Recovery Positive Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c+red_pos) not in SA or (i[0], c*2+r_c) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c+red_pos] < c_max - xbr[i] + c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c+red_pos] = c_max - xbr[i] + c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Positive Cell not faulty, Recovery Negative Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c+red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                    xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Positive Cell Faulty-SA_1, Recovery Negative Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c+red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c+red_pos] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c+red_pos] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                        # Corresponding negative cell SA_1\n",
        "                        if(i[0], i[1]+c) in SA_1:\n",
        "                            \n",
        "                            # Recovery Positive Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c+red_pos) not in SA or (i[0], c*2+r_c) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                    xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Positive Cell not faulty, Recovery Negative Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c+red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Positive Cell Faulty-SA_1, Recovery Negative Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c+red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c+red_pos] < c_max - xbr[i] + c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c+red_pos] = c_max - xbr[i] + c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "\n",
        "\n",
        "                if c<=i[1] < c*2:\n",
        "                    if xbr[i] > c_min:\n",
        "                        \n",
        "                        r_c = random.choice(range(red_pos, red_cols))\n",
        "                        \n",
        "                        # Corresponding Positive cell not faulty or SA_0\n",
        "                        if(i[0], i[1]-c) not in SA or (i[0], i[1]-c) in SA_0:\n",
        "                            \n",
        "                            # Recovery Negative Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) not in SA or (i[0], c*2+r_c) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c-red_pos] < c_max - xbr[i] + c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c-red_pos] = c_max - xbr[i] + c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell not faulty, Recovery Positive Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                    xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell Faulty-SA_1, Recovery Positive Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c-red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c-red_pos] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c-red_pos] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                        \n",
        "                        # Corresponding Positive cell SA_1            \n",
        "                        if(i[0], i[1]-c) in SA_1:\n",
        "                            \n",
        "                            # Recovery Negative Cell or Recovery Negative Cell not Faulty\n",
        "                            if (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) not in SA or (i[0], c*2+r_c-red_pos) in SA_0:\n",
        "                                \n",
        "                                # Recovery Positive Cell less than Cell Value\n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                    xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell not faulty, Recovery Positive Cell Faulty\n",
        "                            elif (i[0], c*2+r_c) not in SA and (i[0], c*2+r_c-red_pos) in SA_1:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                    xbr_f[i[0],c*2+r_c] = c_max\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "                                    \n",
        "                            # Recovery Negative Cell Faulty-SA_1, Recovery Positive Cell  not Faulty\n",
        "                            elif (i[0], c*2+r_c) in SA_1 and (i[0], c*2+r_c-red_pos) not in SA:                      \n",
        "\n",
        "                                if xbr_f[i[0],c*2+r_c-red_pos] < c_max - xbr[i] + c_min:\n",
        "                                    xbr_f[i[0],c*2+r_c-red_pos] = c_max - xbr[i] + c_min\n",
        "\n",
        "                                    mappings.append([i, r_c])\n",
        "\n",
        "            \n",
        "    return xbr_f, mappings "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DlZ9m_y2ZXS3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def combined(xbr, defects,  c, conductance_values, seed_val=0):\n",
        "    \n",
        "    '''\n",
        "    This process uses the approach of both redundant columns and the existing cells which\n",
        "    is an approach tending to use the advantges of both methods while taking advantage of the\n",
        "    pitfalls of the other method\n",
        "    \n",
        "    Parameters:\n",
        "    ------------\n",
        "    xbr: matrix or numpy array\n",
        "            This is the crossbar array with additional redundant columns without defects added. \n",
        "            It is used for comparison purposes to help find the original values of the affected cells\n",
        "        \n",
        "    defects:dictionary\n",
        "            This contains the faulty crossbars, the cells with specific faults\n",
        "            defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "            defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "            defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "    \n",
        "    c: integer value\n",
        "            The number of columns in the original weight without split to help determine where positive\n",
        "            and negative values are seperated.\n",
        "    \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "            Contains the calculated conductance values and range\n",
        "            \n",
        "            c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "            c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "            cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "            \n",
        "    Return:\n",
        "    ---------\n",
        "    output: a dictionary for output\n",
        "        \n",
        "        output[\"f_xbr\"]:      ----------- The finally rectified crossbar\n",
        "        output[\"both_faulty\"]:----------- Cells which are faulty on both the positive and negaative sides\n",
        "        output[\"mapping\"]:    ----------- This is an array containing the cells and their corresponding \n",
        "                                          redundant columns used in overcoming the fault        \n",
        "    '''\n",
        "    \n",
        "    # Extract conductance Values\n",
        "    c_min = conductance_values[\"c_min\"]\n",
        "    c_max = conductance_values[\"c_max\"]\n",
        "    \n",
        "    # Extract the defects\n",
        "    xbr_f = defects['xbar']\n",
        "    SA_0 = defects['SA_0']\n",
        "    SA_1 = defects['SA_1']\n",
        "    \n",
        "    SA = SA_0 + SA_1\n",
        "    xbr_cols = xbr_f.shape[1]\n",
        "    xbr_or = xbr.shape[1]\n",
        "    red_cols = xbr_cols - c*2\n",
        "    red_pos = int(red_cols/2)\n",
        "    \n",
        "    np.random.seed(seed_val)\n",
        "    mappings = []\n",
        "    faluty_rc = []\n",
        "    both_faulty = []\n",
        "    r_c_rec = []\n",
        "    r_c = 0\n",
        "    \n",
        "    if len(SA)!=0:\n",
        "        \n",
        "#         for x in SA:\n",
        "#         # Identifying Faulty Cells and their corresponding ones\n",
        "#             for j in SA:\n",
        "#                 # Find Cells in the same row which are faulty\n",
        "#                 if x[0] == j[0]:\n",
        "\n",
        "#                     # Check if the cell falls under redundant Columns\n",
        "#                     if j[1] >= c*2:\n",
        "#                         faluty_rc.append(j)\n",
        "\n",
        "#                     # Check for Faulty Cells Whose Corresponding cells are faulty too\n",
        "#                     if x[1] == j[1]-c or x[1] == j[1]+c or x[1]-c == j[1] or x[1]+c == j[1]:\n",
        "#                         if x not in both_faulty and j not in both_faulty:\n",
        "#                             both_faulty.append(x)\n",
        "#                             both_faulty.append(j)\n",
        "    \n",
        "        for i in SA:\n",
        "\n",
        "            # SA0 FAULT HANDLING CRITERIA\n",
        "            if xbr_f[i]==c_min:\n",
        "                # Consider A Positive Cell Stuck At Zero\n",
        "                if i[1] < c:\n",
        "                    if xbr[i] > c_min:\n",
        "                      \n",
        "                        r_c = random.choice(np.arange(red_pos))\n",
        "                        # Case Where the Negative Cell is not Stuck.\n",
        "                        # Can be used to overcome a case where the positive redundant cell is faulty\n",
        "                        if (i[0], i[1]+c) not in SA:\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "                                if (i[0], c*2+r_c+ red_pos) not in SA or (i[0], c*2+r_c+ red_pos) in SA_0:\n",
        "                                    if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                        xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                        mappings.append([i, r_c])\n",
        "                                \n",
        "                                # elif (i[0], c*2+r_c+ red_pos) in SA_1:\n",
        "                                    # xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                    # mappings.append([i, r_c])\n",
        "                            \n",
        "                            elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                if (i[0], c*2+r_c + red_pos) not in SA or (i[0], c*2+r_c + red_pos) in SA_0:\n",
        "                                    if xbr_f[i[0], i[1]+c] < c_max - xbr[i] + c_min:\n",
        "                                        xbr_f[i[0], i[1]+c] = c_max - xbr[i] + c_min\n",
        "                                        mappings.append([i, r_c])\n",
        "\n",
        "                        elif (i[0], i[1]+c) in SA_1 and ((i[0], c*2+r_c+ red_pos) not in SA or (i[0], c*2+r_c+ red_pos) in SA_0):\n",
        "\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "                                xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                mappings.append([i, r_c])\n",
        "                            \n",
        "                            elif (i[0], c*2+r_c) in SA_1:\n",
        "                                mappings.append([i, r_c])\n",
        "                                            \n",
        "                        elif (i[0], i[1]+c) in SA_0:\n",
        "\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "\n",
        "                                if (i[0], c*2+r_c+ red_pos) not in SA or (i[0], c*2+r_c+ red_pos) in SA_0:\n",
        "\n",
        "                                    if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                        xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                        mappings.append([i, r_c])\n",
        "                                \n",
        "                                # elif (i[0], c*2+r_c+ red_pos) in SA_1:\n",
        "                                    # if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                        # xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                        # mappings.append([i, r_c])\n",
        "                            \n",
        "                            elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                if (i[0], c*2+r_c + red_pos) not in SA:\n",
        "\n",
        "                                    if xbr_f[i[0],c*2+r_c+ red_pos] < c_max - xbr[i] + c_min:\n",
        "                                        xbr_f[i[0],c*2+r_c+ red_pos] = c_max - xbr[i] + c_min\n",
        "                                        mappings.append([i, r_c])\n",
        "                \n",
        "                # Consider A Negative Cell Stuck at Zero\n",
        "                if c<=i[1] < c*2:\n",
        "                    if xbr[i] > c_min:\n",
        "\n",
        "                        r_c = random.choice(np.arange(red_pos, red_cols))\n",
        "                        \n",
        "                        # Check Out The corresponding Positive cell\n",
        "                        if (i[0], i[1]-c) not in SA:\n",
        "\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "\n",
        "                                if (i[0], c*2+r_c - red_pos) not in SA or (i[0], c*2+r_c - red_pos) in SA_0:\n",
        "\n",
        "                                    if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                        xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                        mappings.append([i, r_c])\n",
        "                                \n",
        "                                # elif (i[0], c*2+r_c - red_pos) in SA_1:\n",
        "                                    # if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                        # xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                        # mappings.append([i, r_c])\n",
        "                            \n",
        "                            elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                if (i[0], c*2+r_c - red_pos) not in SA or (i[0], c*2+r_c - red_pos) in SA_0:\n",
        "                                    \n",
        "                                    if xbr_f[i[0], i[1]-c] < c_max - xbr[i] + c_min:\n",
        "                                        \n",
        "                                        xbr_f[i[0], i[1]-c] = c_max - xbr[i] + c_min\n",
        "                                        mappings.append([i, r_c])\n",
        "\n",
        "                        elif (i[0], i[1]-c) in SA_0:\n",
        "\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "\n",
        "                                if (i[0], c*2+r_c - red_pos) not in SA or (i[0], c*2+r_c - red_pos) in SA_0:\n",
        "\n",
        "                                    if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                        xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                        mappings.append([i, r_c])\n",
        "                                \n",
        "                                # elif (i[0], c*2+r_c - red_pos) in SA_1:\n",
        "                                    # xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                    # mappings.append([i, r_c])\n",
        "                            elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                if (i[0], c*2+r_c - red_pos) not in SA:\n",
        "\n",
        "                                    if xbr_f[i[0],c*2+r_c - red_pos] < c_max - xbr[i] + c_min:\n",
        "                                        xbr_f[i[0],c*2+r_c - red_pos] = c_max - xbr[i] + c_min\n",
        "                                        mappings.append([i, r_c])\n",
        "\n",
        "                        elif (i[0], i[1]-c) in SA_1:\n",
        "\n",
        "                            if (i[0], c*2+r_c) not in SA:\n",
        "                                \n",
        "                                if (i[0], c*2+r_c - red_pos) not in SA and  xbr_f[i[0], c*2+r_c - red_pos] == c_min:\n",
        "\n",
        "                                    if xbr_f[i[0], c*2+r_c - red_pos] >= c_min:\n",
        "                                        xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                        mappings.append([i, r_c])\n",
        "                                    \n",
        "                            elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                # if (i[0], c*2+r_c - red_pos) not in SA and xbr_f[i[0], c*2+r_c - red_pos] == c_min:\n",
        "                                mappings.append([i, r_c])\n",
        "\n",
        "            # SA1 FAULT HANDLING CRITERIA\n",
        "            if xbr_f[i] == c_max:\n",
        "                if i[1] < c:\n",
        "                    if xbr[i] > c_min:\n",
        "                        if red_pos == 0:\n",
        "                            pass\n",
        "                        else:\n",
        "                            r_c = random.choice(np.arange(red_pos))\n",
        "\n",
        "                            # All the other recovery cells are not faulty\n",
        "                            if (i[0], i[1]+c) not in SA:\n",
        "\n",
        "                                xbr_f[i[0], i[1]+c] = c_max - xbr[i] + c_min\n",
        "\n",
        "                            else:                                \n",
        "                                # Corresponding Negative cell is not faulty\n",
        "                                # if (i[0], i[1]+c) in SA_0:\n",
        "\n",
        "                                    # Non Faulty Redundant Positive Column\n",
        "                                    # if (i[0], c*2+r_c) not in SA:\n",
        "                                        # Faulty Redundant Negative Column - SA-1\n",
        "                                        # if (i[0], c*2+r_c+ red_pos) in SA_1:\n",
        "\n",
        "                                            # if xbr_f[i[0], c*2+r_c] < xbr[i]:\n",
        "                                                # xbr_f[i[0], c*2+r_c] = xbr[i]\n",
        "                                                # mappings.append([i, r_c])\n",
        "                                                \n",
        "                                # Corresponding Negative Cell Faulty SA-0\n",
        "                                if (i[0], i[1]+c) in SA_0:\n",
        "                                    # Redundant Negative Column Cell not Faulty\n",
        "                                    if (i[0], c*2+r_c+ red_pos) not in SA:\n",
        "                                        # Redundant Positive Column Cell Not Faulty\n",
        "                                        if (i[0], c*2+r_c) not in SA or (i[0], c*2+r_c) in SA_0:\n",
        "                                            if xbr_f[i[0],c*2+r_c + red_pos] < c_max - xbr[i] + c_min:\n",
        "                                                xbr_f[i[0],c*2+r_c+ red_pos] = c_max - xbr[i] + c_min\n",
        "                                                mappings.append([i, r_c])\n",
        "\n",
        "                                    # Redundant Negative Column Cell Faulty - SA-1\n",
        "                                    elif (i[0], c*2+r_c+ red_pos) in SA_1:\n",
        "                                        if (i[0], c*2+r_c) not in SA:\n",
        "                                            if xbr_f[i[0], c*2+r_c] < xbr[i]:\n",
        "                                                xbr_f[i[0], c*2+r_c] = xbr[i]\n",
        "                                                mappings.append([i, r_c])\n",
        "                                                \n",
        "                                            elif (i[0], c*2+r_c) in SA_0:\n",
        "                                                mappings.append([i, r_c])\n",
        "\n",
        "                                    # Redundant Positive Column Cell Faulty - SA-1\n",
        "                                    # elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                        # Redundant Negative Column Cell Not Faulty\n",
        "                                        # if (i[0], c*2+r_c + red_pos) not in SA:\n",
        "\n",
        "                                            # if xbr_f[i[0],c*2+r_c+ red_pos] < c_max:\n",
        "                                                # xbr_f[i[0],c*2+r_c+ red_pos] = c_max\n",
        "                                                # mappings.append([i, r_c])\n",
        "\n",
        "                                    # Redundant Positive Column Cell Faulty - SA-0\n",
        "                                    elif (i[0], c*2+r_c) in SA_0:\n",
        "\n",
        "                                        if (i[0], c*2+r_c + red_pos) not in SA:\n",
        "\n",
        "                                            if xbr_f[i[0],c*2+r_c+ red_pos] < c_max - xbr[i] + c_min:\n",
        "                                                xbr_f[i[0],c*2+r_c+ red_pos] = c_max - xbr[i] + c_min\n",
        "                                                mappings.append([i, r_c])\n",
        "                                                \n",
        "                                        elif (i[0], c*2+r_c + red_pos) in SA_1:\n",
        "                                            mappings.append([i, r_c])\n",
        "\n",
        "                                # Corresponding Negative Cell Faulty - SA-1\n",
        "                                elif (i[0], i[1]+c) in SA_1:\n",
        "\n",
        "                                    # Redundant Positive Cell not Faulty\n",
        "                                    if (i[0], c*2+r_c) not in SA:\n",
        "\n",
        "                                        # Redundant Negative Cell Not Faulty or SA-0\n",
        "                                        if (i[0], c*2+r_c+ red_pos) not in SA or (i[0], c*2+r_c+ red_pos) in SA_0:\n",
        "\n",
        "                                            if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                                xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                                mappings.append([i, r_c])\n",
        "\n",
        "                                        # Redundant Negative Cell Faulty - SA-1\n",
        "                                        # if (i[0], c*2+r_c+ red_pos) in SA_1:\n",
        "\n",
        "                                            # if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "\n",
        "                                                # xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                                # mappings.append([i, r_c])\n",
        "\n",
        "                                    # Redundant Positive cell Faulty -  SA-1\n",
        "                                    elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                        # Redundant Negative Cell not Faulty\n",
        "                                        if (i[0], c*2+r_c + red_pos) not in SA:\n",
        "\n",
        "                                            if xbr_f[i[0],c*2+r_c+ red_pos] < c_max - xbr[i] + c_min:\n",
        "                                                xbr_f[i[0],c*2+r_c+ red_pos] = c_max - xbr[i] + c_min\n",
        "                                                mappings.append([i, r_c])\n",
        "\n",
        "\n",
        "                if c<=i[1] < c*2:\n",
        "                    # Negative Cell Faulty\n",
        "                    if xbr[i] < c_max:\n",
        "                        if red_pos == 0:\n",
        "                            pass\n",
        "                        else:\n",
        "                            r_c = random.choice(np.arange(red_pos, red_cols))\n",
        "\n",
        "                            # All other Cells are fault Free\n",
        "                            if (i[0], i[1]-c) not in SA:\n",
        "\n",
        "                                xbr_f[i[0], i[1]-c] = c_max - xbr[i] + c_min\n",
        "\n",
        "                            else:\n",
        "                                # Positive Cell Not Faullty\n",
        "#                                 if (i[0], i[1]-c) not in SA:\n",
        "\n",
        "#                                     # Negative Redundant Cell Not Faulty\n",
        "#                                     if (i[0], c*2+r_c) not in SA:\n",
        "\n",
        "#                                         # Positive Redundant Cell Faulty - SA-1\n",
        "#                                         if (i[0], c*2+r_c - red_pos) in SA_1:\n",
        "#                                             if xbr_f[i[0],c*2+r_c] < xbr[i]:                                                \n",
        "#                                                 xbr_f[i[0],c*2+r_c] = c_max - xbr[i] + c_min\n",
        "#                                                 mappings.append([i, r_c])\n",
        "\n",
        "#                                         # Positive Redundant Cell Faulty - SA-0\n",
        "#                                         if (i[0], c*2+r_c - red_pos) in SA_0:\n",
        "#                                             if xbr_f[i[0], i[1]-c] < c_max - xbr[i] + c_min:\n",
        "#                                                 xbr_f[i[0], i[1]-c] = c_max - xbr[i] + c_min\n",
        "\n",
        "#                                     # Negative Redundant Cell Faulty - SA-1\n",
        "#                                     elif (i[0], c*2+r_c) in SA_1:\n",
        "#                                         if (i[0], c*2+r_c - red_pos) not in SA:\n",
        "#                                             if xbr_f[i[0],c*2+r_c - red_pos] < c_max :\n",
        "#                                                 xbr_f[i[0],c*2+r_c - red_pos] = c_max\n",
        "#                                                 xbr_f[i[0], i[1]-c] = c_max - xbr[i] + c_min\n",
        "#                                                 mappings.append([i, r_c])\n",
        "\n",
        "#                                     # Negative Redundant Cell Faulty - SA-0\n",
        "#                                     elif (i[0], c*2+r_c) in SA_0:\n",
        "\n",
        "#                                         if (i[0], c*2+r_c - red_pos) not in SA:\n",
        "#                                             xbr_f[i[0], i[1]-c] = c_max - xbr[i] + c_min\n",
        "                                \n",
        "                                # Positive Cell Faulty - SA-0\n",
        "                                if (i[0], i[1]-c) in SA_0:\n",
        "                                    # Positive Redundant Cell not Faulty\n",
        "                                    if (i[0], c*2+r_c - red_pos) not in SA:\n",
        "                                        # Redundant Negative Cell not Faulty\n",
        "                                        if (i[0], c*2+r_c) not in SA or (i[0],c*2+r_c) in SA_0:\n",
        "                                            if xbr_f[i[0],c*2+r_c - red_pos] < c_max - xbr[i] + c_min:\n",
        "                                                xbr_f[i[0],c*2+r_c - red_pos] = c_max - xbr[i] + c_min\n",
        "                                                mappings.append([i, r_c])\n",
        "\n",
        "                                        # Positive Redundant Cell Faulty - SA-1\n",
        "                                    elif (i[0], c*2+r_c - red_pos) in SA_1:\n",
        "                                        if (i[0], c*2+r_c) not in SA:\n",
        "                                            if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                                xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                                mappings.append([i, r_c])\n",
        "                                                \n",
        "                                        elif (i[0], c*2+r_c) in SA_0:\n",
        "                                            mappings.append([i, r_c])\n",
        "\n",
        "                                        # Positive Redundant Cell Faulty - SA-0\n",
        "                                        # elif (i[0], c*2+r_c - red_pos) in SA_0:\n",
        "\n",
        "                                            # if xbr_f[i[0],c*2+r_c] > c_min:\n",
        "                                                # xbr_f[i[0],c*2+r_c] = c_min\n",
        "                                                # mappings.append([i, r_c])\n",
        "\n",
        "                                    # Negative Redundant Cell Faulty - SA-1\n",
        "                                    # elif (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                        # Positive Redundant Cell Not Faulty\n",
        "                                        # if (i[0], c*2+r_c - red_pos) not in SA:\n",
        "\n",
        "                                            # if xbr_f[i[0],c*2+r_c - red_pos] < c_max :\n",
        "                                                # xbr_f[i[0],c*2+r_c - red_pos] = c_max\n",
        "                                                # mappings.append([i, r_c])\n",
        "\n",
        "\n",
        "                                # Positive Cell Faulty - SA-1\n",
        "                                if (i[0], i[1]-c) in SA_1:\n",
        "\n",
        "                                    # Negative Redundant Cell Not Faulty\n",
        "                                    if (i[0], c*2+r_c) not in SA:\n",
        "\n",
        "                                        # Positive Redundant Cell Not Faulty or SA-0\n",
        "                                        if (i[0], c*2+r_c - red_pos) not in SA or (i[0], c*2+r_c - red_pos) in SA_0:\n",
        "\n",
        "                                            if xbr_f[i[0],c*2+r_c] < xbr[i]:\n",
        "                                                xbr_f[i[0],c*2+r_c] = xbr[i]\n",
        "                                                mappings.append([i, r_c])\n",
        "\n",
        "                                        # Positive Redundant Cell Faulty - SA-1\n",
        "                                        # if (i[0], c*2+r_c - red_pos) in SA_1:\n",
        "                                            # if xbr_f[i[0],c*2+r_c] < c_max:\n",
        "                                                # xbr_f[i[0],c*2+r_c] = c_max\n",
        "                                                # mappings.append([i, r_c])\n",
        "\n",
        "                                    # Negative Redundant Cell Faulty - SA-1\n",
        "                                    if (i[0], c*2+r_c) in SA_1:\n",
        "\n",
        "                                        # Positive Redundant Cell Not Faulty\n",
        "                                        if (i[0], c*2+r_c - red_pos) not in SA:\n",
        "                                            if xbr_f[i[0], c*2+r_c - red_pos] < c_max - xbr[i] + c_min:\n",
        "                                                xbr_f[i[0],c*2+r_c - red_pos] = c_max - xbr[i] + c_min\n",
        "                                                mappings.append([i, r_c])\n",
        "                \n",
        "    output = {\n",
        "        \"f_xbr\":xbr_f,\n",
        "        # \"both_faulty\":both_faulty,\n",
        "        \"mapping\":mappings\n",
        "    }\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hUoHyqr9ZbyR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def proposed_approach(xbar_or, defects, recovery_cells, conductance_values):# xbr_f, xbr, SA_0, SA_1,  c, c_min, c_max, group_cell, pos, neg, red):\n",
        "    \n",
        "    '''    \n",
        "    Rectify the faults on the proposed split crossbar of 4X5. One redundant cell is used to overcome\n",
        "    a fault that cannot be done by the four cells mostly if both the positive and negative corresponding\n",
        "    cells are faulty\n",
        "    \n",
        "    Parameters:\n",
        "    -------------\n",
        "    \n",
        "    defects:dictionary\n",
        "            This contains the faulty crossbars, the cells with specific faults\n",
        "            defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "            defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "            defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "            \n",
        "    xbar: matrix or numpy array\n",
        "            This is the crossbar array with 4X5 splits without defects added. \n",
        "            It is used for comparison purposes to help find the original values of the affected cells\n",
        "            \n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "            Contains the calculated conductance values and range\n",
        "            \n",
        "            c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "            c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "            cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "            \n",
        "    Return:\n",
        "    ---------\n",
        "    \n",
        "    xbar_f:matrix or numpy array\n",
        "            \n",
        "            Crossbar with cells that have been rectified\n",
        "            \n",
        "    cell_mapping:numpy array\n",
        "            \n",
        "    '''\n",
        "    # Extract conductance Values\n",
        "    c_min = conductance_values['c_min']\n",
        "    c_max = conductance_values['c_max']\n",
        "    \n",
        "    # Extract the defects\n",
        "    xbar_f = defects['xbar']\n",
        "    SA_0 = defects['SA_0']\n",
        "    SA_1 = defects['SA_1']\n",
        "    \n",
        "    fc = SA_0 + SA_1\n",
        "    # print(\"defects['f_cells'] == fc: {}\".format(faulty_cells == fc))\n",
        "    # print(\"defects['f_cells']: {}\\nfc: {}\".format(faulty_cells,fc))\n",
        "    # print(\"SA_1: {}, Cells: {}\".format(len(SA_1),SA_1))\n",
        "    cell_mapping = []\n",
        "    \n",
        "    # Writing a positive Value to a positive affected cell\n",
        "    # print(\"Faulty grouped: \", cells_considered)\n",
        "    \n",
        "    if len(recovery_cells) !=0:\n",
        "        \n",
        "        for mod_cell in recovery_cells:\n",
        "            pos_cell = mod_cell[0]\n",
        "            neg_cell = mod_cell[1]\n",
        "            rec_pos = mod_cell[2]\n",
        "            rec_neg = mod_cell[3]\n",
        "            \n",
        "            # POSITITVE CELL FAULTY\n",
        "        \n",
        "            # Positive Cell Faulty SA_0\n",
        "            if pos_cell in SA_0:\n",
        "                if xbar_or[pos_cell] != c_min:\n",
        "                    # Redundant Column Cell not Faulty\n",
        "                    if rec_pos not in fc:\n",
        "                        if rec_neg not in fc or rec_neg in SA_0:\n",
        "                            # Use Redundant cell to overcome the fault\n",
        "                            if xbar_f[rec_pos] < xbar_or[pos_cell]:\n",
        "                                xbar_f[rec_pos] = xbar_or[pos_cell]\n",
        "                                cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                    # Redundant Column Cell Faulty - SA-1\n",
        "                    # No Changes can be preformed when the redundant cell is faulty at SA-0\n",
        "                    elif rec_pos in SA_1:                            \n",
        "                        if rec_neg not in fc or rec_neg in SA_0:\n",
        "                            # Negative Corresponding Cell not Faulty\n",
        "                            if neg_cell not in fc:\n",
        "                                if xbar_f[neg_cell] < c_max - xbar_or[pos_cell] + c_min:\n",
        "                                    xbar_f[neg_cell] = c_max - xbar_or[pos_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                            # Negative Corresponding Cell Faulty - SA-0\n",
        "                            elif neg_cell in SA_0:\n",
        "                                if xbar_f[rec_neg] < c_max - xbar_or[pos_cell] + c_min and rec_neg not in fc:\n",
        "                                    xbar_f[rec_neg] = c_max - xbar_or[pos_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                            # Negative Corresponding Cell Faulty - SA-1\n",
        "                            elif neg_cell in SA_1:\n",
        "                                cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "            # Positive Cell Faulty - SA-1                    \n",
        "            elif pos_cell in SA_1:\n",
        "                if xbar_or[pos_cell] != c_min:\n",
        "                    if neg_cell not in fc:\n",
        "                        # Use Redundant cell to overcome the fault\n",
        "                        if xbar_f[neg_cell] < c_max - xbar_or[pos_cell] + c_min:\n",
        "                            xbar_f[neg_cell] = c_max - xbar_or[pos_cell] + c_min\n",
        "                                \n",
        "                    # When the Corresponding negative cell is faulty\n",
        "                    # We can only reduce the error margin by setting the redundant cell to c_min\n",
        "                    elif neg_cell in SA_1:\n",
        "                        if rec_pos not in fc:\n",
        "                            if rec_neg not in fc or rec_neg in SA_0:\n",
        "                                if xbar_f[rec_pos] < xbar_or[pos_cell]:\n",
        "                                    xbar_f[rec_pos] = xbar_or[pos_cell]\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                            \n",
        "                        elif rec_pos in SA_1:\n",
        "                            if rec_neg not in fc:\n",
        "                                if xbar_f[rec_neg] < c_max - xbar_or[pos_cell] + c_min:\n",
        "                                    xbar_f[rec_neg] = c_max - xbar_or[pos_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                                    \n",
        "                    elif neg_cell in SA_0:\n",
        "                        if rec_neg not in fc and (rec_pos not in fc or rec_pos in SA_0):\n",
        "                            if xbar_f[rec_neg] < c_max - xbar_or[pos_cell] + c_min:\n",
        "                                xbar_f[rec_neg] = c_max - xbar_or[pos_cell] + c_min\n",
        "                                cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                                \n",
        "                        elif rec_neg in SA_1:\n",
        "                            if rec_pos not in fc:\n",
        "                                if xbar_f[rec_pos] < xbar_or[pos_cell]:\n",
        "                                    xbar_f[rec_pos] = xbar_or[pos_cell]\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                                    \n",
        "                            if rec_pos in SA_0:\n",
        "                                cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "            \n",
        "            \n",
        "            # NEGATIVE CELL FAULTY\n",
        "            \n",
        "            # Negative Cell Faulty - SA-0\n",
        "            elif neg_cell in SA_0:\n",
        "                if xbar_or[neg_cell] != c_min:\n",
        "                    # Redundant Column Cell not Faulty\n",
        "                    if rec_neg not in fc:\n",
        "                        if rec_pos not in fc or rec_pos in SA_0:\n",
        "                            # Use Redundant cell to overcome the fault\n",
        "                            # Positive Corresponding Cell not Faulty\n",
        "                            if pos_cell not in fc or pos_cell in SA_0:\n",
        "                                if xbar_f[rec_neg] < xbar_or[neg_cell]:\n",
        "                                    xbar_f[rec_neg] = xbar_or[neg_cell]\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                                \n",
        "                            if pos_cell in SA_1:\n",
        "                                if xbar_f[rec_neg] < c_max:\n",
        "                                    xbar_f[rec_neg] = c_max\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                    # Redundant Column Cell Faulty - SA-1\n",
        "                    # No Changes can be preformed when the redundant cell is faulty at SA-0\n",
        "                    elif rec_neg in SA_1:\n",
        "                        if pos_cell not in fc:\n",
        "                            if rec_pos not in fc or rec_pos in SA_0:\n",
        "                                if xbar_f[pos_cell] < c_max - xbar_or[neg_cell] + c_min:\n",
        "                                    xbar_f[pos_cell] = c_max - xbar_or[neg_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                        elif pos_cell in SA_0:\n",
        "                            if rec_pos not in fc:\n",
        "                                if xbar_f[rec_pos] < c_max - xbar_or[neg_cell] + c_min:\n",
        "                                    xbar_f[rec_pos] = c_max - xbar_or[neg_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                        elif pos_cell in SA_1:\n",
        "                            if rec_pos not in fc or rec_pos in SA_0:\n",
        "                                cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "            \n",
        "            # Negative Cell Faulty - SA-1                    \n",
        "            elif neg_cell in SA_1:\n",
        "                if xbar_or[neg_cell] != c_min:\n",
        "                    if pos_cell not in fc:\n",
        "                        # Use Redundant cell to overcome the fault\n",
        "                        if xbar_f[pos_cell] < c_max - xbar_or[neg_cell] + c_min:\n",
        "                            xbar_f[pos_cell] = c_max - xbar_or[neg_cell] + c_min\n",
        "                            # cell_mapping.append([pos_cell, neg_cell])\n",
        "                                \n",
        "                    # Corresponding positive cell is faulty - SA-0\n",
        "                    elif pos_cell in SA_0:\n",
        "                        if rec_pos not in fc:\n",
        "                            # Redundant Cell not Faulty\n",
        "                            # No change can be made if the cell is faulty\n",
        "                            if rec_neg not in fc or rec_neg in SA_0:\n",
        "                                if xbar_f[rec_pos] < c_max - xbar_or[neg_cell] + c_min: \n",
        "                                    xbar_f[rec_pos] = c_max - xbar_or[neg_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                                    \n",
        "                        elif rec_pos in SA_1:\n",
        "                            if rec_neg not in fc:\n",
        "                                if xbar_f[rec_neg] < xbar_or[neg_cell]: \n",
        "                                    xbar_f[rec_neg] = xbar_or[neg_cell]\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                            \n",
        "                            elif rec_neg in SA_0:\n",
        "                                cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                    \n",
        "                    # Corresponding Positive Cell Faulty - SA-1\n",
        "                    elif pos_cell in SA_1:\n",
        "                        if rec_neg not in fc:\n",
        "                            # Redundant Cell not Faulty\n",
        "                            if rec_pos not in fc or rec_pos in SA_0:\n",
        "                                if xbar_f[rec_neg] < xbar_or[neg_cell]: \n",
        "                                    xbar_f[rec_neg] = xbar_or[neg_cell]\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "\n",
        "                        # Redundant Cell not Faulty\n",
        "                        elif rec_neg in SA_1:\n",
        "                            if rec_pos not in fc:\n",
        "                                if xbar_f[rec_pos] < c_max - xbar_or[neg_cell] + c_min: \n",
        "                                    xbar_f[rec_pos] = c_max - xbar_or[neg_cell] + c_min\n",
        "                                    cell_mapping.append([pos_cell, neg_cell, rec_pos, rec_neg])\n",
        "                                    \n",
        "    else:\n",
        "    # No Faulty Cells, Keep the cell values\n",
        "        xbar_f = xbar_or\n",
        "        cell_mapping = []\n",
        "                    \n",
        "    return xbar_f, cell_mapping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGebPQf6ZgI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bit_level_precision(conductance_values, \n",
        "                        w_con, \n",
        "                        n, \n",
        "                        max_w_b):\n",
        "    \n",
        "    '''\n",
        "    This converts the weights passed to it to take up the bit levels as defined\n",
        "    The number of bits alter the conductance value ranges and conductance values mapped to the crossbar\n",
        "    \n",
        "    Parameters:\n",
        "    ------------\n",
        "    conductance_values: dictionary of memristor resistance and conductance range\n",
        "            \n",
        "        Contains the calculated conductance values and range\n",
        "\n",
        "        c_min      = conductance_values['c_min']  .............. Minimum Conductance\n",
        "        c_max      = conductance_values['c_max']  .............. Maximum Conductance\n",
        "        cond_range = conductance_values['c_range'].............. Conductance Range\n",
        "        \n",
        "    w_con: matrix or numpy array\n",
        "            This is the final crossbar array with with faults fixed. \n",
        "            It is converted to correspond to the number of bits that we would like the memristor to hold\n",
        "        \n",
        "    n: integer value\n",
        "            The number of bits to represent the memristor bits storage level.\n",
        "            The more the number of bits, the better the accuracy as manifested in some experiments\n",
        "            \n",
        "    max_val: float or double\n",
        "        The maximum absolute value in the weight matrix to be used in determining the conductance\n",
        "        split\n",
        "            \n",
        "    Return:\n",
        "    ---------\n",
        "    w: matrix or numpy array\n",
        "\n",
        "        The finally rectified crossbar\n",
        "\n",
        "    div_pattern: array\n",
        "\n",
        "        An array containing the division pattern of the memristor. This depends entirely on the number of\n",
        "        bits that we specify. The number of divisions is equivalent to 2^n - 1 where n is the number of bits\n",
        "        \n",
        "    '''\n",
        "    # Extract Conductance values\n",
        "    min_cond = conductance_values['c_min']\n",
        "    max_cond = conductance_values['c_max']\n",
        "    cond_rng = conductance_values['c_range']\n",
        "    \n",
        "    divs = pow(2, n) - 1\n",
        "    div_pattern = np.linspace(min_cond, max_cond, divs)\n",
        "    F_w = (((w_con - min_cond)/cond_rng)* divs).round()\n",
        "    \n",
        "    w_bits_con = ((F_w* cond_rng)/divs)+min_cond\n",
        "\n",
        "    # Alternatively\n",
        "    # divs = pow(2, n)\n",
        "    # div_pattern = np.linspace(min_cond, max_cond, divs)\n",
        "    # F_w = ((((w_con - min_cond)/cond_rng)* divs)- 0.5).round()\n",
        "\n",
        "    # w_bits_con = (((F_w + 0.5)* cond_rng)/divs)+min_cond \n",
        "    \n",
        "    # w = ((w_bits_con - min_cond)/cond_rng)*max_w_b\n",
        "\n",
        "    #Weight Adjustment - Corresponding to the Conductance Range\n",
        "    # w_bits = adjust_con_weights(w_bits_con, div_pattern)\n",
        "    \n",
        "    w = ((w_bits_con - min_cond)/cond_rng)*max_w_b\n",
        "\n",
        "    # return w_bits, div_pattern\n",
        "    return w, div_pattern"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXvw87ogZjbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xbar_output(xba, w_r, w_c):\n",
        "    \n",
        "    '''\n",
        "    Visualize the crossbar array with or without defects for every leyer\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    w_r: integer value\n",
        "        \n",
        "        The number of rows in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    w_c: integer value\n",
        "        \n",
        "        The number of columns in the original pretrained weight that we are mapping to the memristor\n",
        "        \n",
        "     Returns:\n",
        "    ----------\n",
        "    xba_final: An n-d array or matrix\n",
        "        \n",
        "        An array of conductance values that is of the same size as the originally pretrained weight\n",
        "        ready for testing using the prediction model of the neural network during the evaluation of\n",
        "        it's performance\n",
        "    \n",
        "    '''    \n",
        "    tot_rows, tot_cols = xba.shape\n",
        "    r_cols = tot_cols - w_c*2\n",
        "    r_pos = r_cols//2\n",
        "    \n",
        "    xba_final = []\n",
        "    \n",
        "    pos_xbr_cells = slice(0, w_c)\n",
        "    neg_xbr_cells = slice(w_c, w_c*2)\n",
        "        \n",
        "    xba_final = xba[:,pos_xbr_cells]-xba[:,neg_xbr_cells]\n",
        "    \n",
        "    return xba_final[:w_r+1,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qzaPcd95ZmoF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xbar_output_red_col(xba, w_r, w_c, red_cols, defects, all_cells):\n",
        "    \n",
        "    '''\n",
        "    Visualize the crossbar array with or without defects for every leyer\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    w_r: integer value\n",
        "        \n",
        "        The number of rows in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    w_c: integer value\n",
        "        \n",
        "        The number of columns in the original pretrained weight that we are mapping to the memristor\n",
        "        \n",
        "    red_cols: an array\n",
        "    \n",
        "        Array containing all memristor cells which are the redundant columns used in overcoming the faults\n",
        "        in the crossbar\n",
        "    \n",
        "    defects:dictionary\n",
        "    \n",
        "        This contains the faulty crossbars, the cells with specific faults\n",
        "        defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "        defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "        defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "           \n",
        "    f_both: an array\n",
        "    \n",
        "        Array containing all memristor cells which are considered faulty on both the positive and negative side\n",
        "        They are considered irrecoverable\n",
        "        \n",
        "    all_cells: an array\n",
        "    \n",
        "        Array containing all memristor cells in the crossbar\n",
        "        \n",
        "    \n",
        "    f_gp_cells: an array\n",
        "    \n",
        "        Array containing all faulty memristor cells grouped with the redundant cells used for overcoming the fault\n",
        "    \n",
        "     Returns:\n",
        "    ----------\n",
        "    xba_final: An n-d array or matrix\n",
        "        \n",
        "        An array of conductance values that is of the same size as the originally pretrained weight\n",
        "        ready for testing using the prediction model of the neural network during the evaluation of\n",
        "        it's performance\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Extract Defects\n",
        "    SA0 = defects['SA_0']\n",
        "    SA1 = defects['SA_1']\n",
        "    \n",
        "    tot_rows, tot_cols = xba.shape\n",
        "    r_cols = tot_cols - w_c*2\n",
        "    r_pos = int(r_cols/2)\n",
        "    f_c = SA0 + SA1\n",
        "    \n",
        "    global xba_final\n",
        "    \n",
        "    pos_xbr_cells = slice(0, w_c)\n",
        "    neg_xbr_cells = slice(w_c, w_c*2)\n",
        "    \n",
        "    xba_final = xbar_output(xba, tot_rows, w_c)\n",
        "    \n",
        "    if len(red_cols) != 0:\n",
        "        \n",
        "        # print(\"red_cols: \", red_cols)\n",
        "        \n",
        "        for r_cell in red_cols:\n",
        "            \n",
        "            # print(\"r_cell: \", r_cell)\n",
        "        \n",
        "        # Check if the cell is among the grouped cells which use redundant columns\n",
        "\n",
        "            if r_cell[0][1] < w_c:\n",
        "                if r_cell[1] < r_pos:\n",
        "\n",
        "                    xba_final[r_cell[0][0], r_cell[0][1]] = xba_final[r_cell[0][0], r_cell[0][1]] + xba[r_cell[0][0],r_cell[1]+w_c*2]- xba[r_cell[0][0],r_cell[1]+w_c*2+r_pos]\n",
        "\n",
        "                if r_pos <= r_cell[1] < r_cols:\n",
        "\n",
        "                    xba_final[r_cell[0][0], r_cell[0][1]] = xba_final[r_cell[0][0], r_cell[0][1]] - xba[r_cell[0][0],r_cell[1]+w_c*2] + xba[r_cell[0][0],r_cell[1]+w_c*2-r_pos]\n",
        "\n",
        "            if w_c <= r_cell[0][1] < 2*w_c:\n",
        "\n",
        "                if r_cell[1] < r_pos:\n",
        "\n",
        "                    xba_final[r_cell[0][0], r_cell[0][1]-w_c] = xba_final[r_cell[0][0], r_cell[0][1]-w_c] + xba[r_cell[0][0],r_cell[1]+w_c*2]- xba[r_cell[0][0],r_cell[1]+w_c*2+r_pos]\n",
        "\n",
        "                if r_pos <= r_cell[1] < r_cols:\n",
        "\n",
        "                    xba_final[r_cell[0][0], r_cell[0][1]-w_c] = xba_final[r_cell[0][0], r_cell[0][1]-w_c] - xba[r_cell[0][0],r_cell[1]+w_c*2] + xba[r_cell[0][0],r_cell[1]+w_c*2-r_pos]\n",
        "\n",
        "    return xba_final[:w_r+1,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b_x6B79gZqAz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xbar_output_combined(xba, w_r, w_c, cell_map, defects, all_cells):\n",
        "    \n",
        "    '''\n",
        "    Visualize the crossbar array with or without defects for every leyer\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    w_r: integer value\n",
        "        \n",
        "        The number of rows in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    w_c: integer value\n",
        "        \n",
        "        The number of columns in the original pretrained weight that we are mapping to the memristor\n",
        "        \n",
        "    cell_map: an array\n",
        "    \n",
        "        Array containing all memristor cells which are the redundant columns used in overcoming the faults\n",
        "        in the crossbar\n",
        "    \n",
        "    \n",
        "    defects:dictionary\n",
        "    \n",
        "        This contains the faulty crossbars, the cells with specific faults\n",
        "        defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "        defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "        defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "        \n",
        "    all_cells: an array\n",
        "    \n",
        "        Array containing all memristor cells in the crossbar\n",
        "        \n",
        "    \n",
        "    f_gp_cells: an array\n",
        "    \n",
        "        Array containing all faulty memristor cells grouped with the redundant cells used for overcoming the fault\n",
        "        \n",
        "     Returns:\n",
        "    ----------\n",
        "    xba_final: An n-d array or matrix\n",
        "        \n",
        "        An array of conductance values that is of the same size as the originally pretrained weight\n",
        "        ready for testing using the prediction model of the neural network during the evaluation of\n",
        "        it's performance\n",
        "    \n",
        "    '''    \n",
        "    # Extract Defects\n",
        "    SA0 = defects['SA_0']\n",
        "    SA1 = defects['SA_1']\n",
        "    \n",
        "    tot_rows, tot_cols = xba.shape\n",
        "    r_cols = tot_cols - w_c*2\n",
        "    r_pos = int(r_cols/2)\n",
        "    f_c = SA0 + SA1\n",
        "    \n",
        "    pos_xbr_cells = slice(0, w_c)\n",
        "    neg_xbr_cells = slice(w_c, w_c*2)\n",
        "    \n",
        "    xba_final = xbar_output(xba, xba.shape[0], w_c)\n",
        "    \n",
        "    for cell in all_cells:\n",
        "        for corrected in cell_map:\n",
        "            if cell == corrected[0]:\n",
        "                if cell[1] < w_c:\n",
        "                    if corrected[1] < r_pos:\n",
        "                        xba_final[cell] = xba_final[cell[0],cell[1]] + xba[cell[0],corrected[1]+w_c*2]- xba[cell[0],corrected[1]+w_c*2+r_pos]\n",
        "\n",
        "                    if r_pos <= corrected[1] < r_cols:\n",
        "                        # print('test 2')\n",
        "                        xba_final[cell] = xba_final[cell[0],cell[1]] - xba[cell[0],corrected[1]+w_c*2] + xba[cell[0],corrected[1]+w_c*2-r_pos]\n",
        "\n",
        "                if w_c <= cell[1] < 2*w_c:\n",
        "\n",
        "                    if corrected[1] < r_pos:\n",
        "                        # print('test 3')\n",
        "                        xba_final[cell[0],cell[1]-w_c] = xba_final[cell[0],cell[1]-w_c] + xba[cell[0],corrected[1]+w_c*2] - xba[cell[0],corrected[1]+w_c*2+r_pos]\n",
        "\n",
        "                    if r_pos <= corrected[1] < r_cols:\n",
        "                        # print('test 4')\n",
        "                        xba_final[cell[0],cell[1]-w_c] = xba_final[cell[0],cell[1]-w_c] - xba[cell[0],corrected[1]+w_c*2] + xba[cell[0],corrected[1]+w_c*2-r_pos]\n",
        "\n",
        "    return xba_final[:w_r+1,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ys1ebCEVZtSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xbar_output_prop(xba, w_r, w_c, group_cells, f_gp_cell):\n",
        "    \n",
        "    '''\n",
        "    Visualize the crossbar array with or without defects for every leyer\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    w_r: integer value\n",
        "        \n",
        "        The number of rows in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    w_c: integer value\n",
        "        \n",
        "        The number of columns in the original pretrained weight that we are mapping to the memristor\n",
        "    \n",
        "    defects:dictionary\n",
        "    \n",
        "        This contains the faulty crossbars, the cells with specific faults\n",
        "        defects['xbar'] ------------ Faulty crossbar with cells affected by the introduced faults\n",
        "        defects['SA_0'] ------------ Cells with values stuck at high resistance or low conductance value\n",
        "        defects['SA_1'] ------------ Cells with values stuck at low resistance or high conductance value\n",
        "        \n",
        "    all_cells: an array\n",
        "    \n",
        "        Array containing all memristor cells in the crossbar\n",
        "        \n",
        "    \n",
        "    f_gp_cells: an array\n",
        "    \n",
        "        Array containing all faulty memristor cells grouped with the redundant cells used for overcoming the fault\n",
        "    \n",
        "    pos: an array\n",
        "    \n",
        "        Array containing all memristor cells considered to be on the positive side of the crossbar\n",
        "        \n",
        "    sep: integer value\n",
        "        \n",
        "        The number indicating the number of rows and number of columns to be used in the case of a proposed\n",
        "        architecture.\n",
        "        \n",
        "    fault_tool: can be existing_cells, red_columns, mixed, or proposed\n",
        "        \n",
        "        existing_cells: Uses the exixting cells to overcome the fault in the memristor crossbar\n",
        "                        It does not require any additional hardware in terms of additional memrostor cells\n",
        "                        \n",
        "        red_columns:    Uses the redundant cells to overcome the faults in the memristor crossbar\n",
        "                        It requires an additional number of rows and columns however, the size depends on the \n",
        "                        fault defect percentage\n",
        "                    \n",
        "        mixed:          Combines the behavior of the two approaches above to attain a balanced and more\n",
        "                        robust approach taking advantage of each other.\n",
        "        \n",
        "        proposed:       Use the proposed approach to overcome the fault on the memristor crossbar\n",
        "        \n",
        "     Returns:\n",
        "    ----------\n",
        "    xba_final: An n-d array or matrix\n",
        "        \n",
        "        An array of conductance values that is of the same size as the originally pretrained weight\n",
        "        ready for testing using the prediction model of the neural network during the evaluation of\n",
        "        it's performance\n",
        "    \n",
        "    '''\n",
        "    # Extract Cells from the group\n",
        "    # pos = group_cells['positive']\n",
        "    # neg_cell_ = group_cells['negative']\n",
        "    # red_cell_ = group_cells['redundant']\n",
        "    \n",
        "    all_cells = group_cells['groups']\n",
        "    \n",
        "    #print(\"all_cells\\n\", len(all_cells))\n",
        "    \n",
        "    tot_rows, tot_cols = xba.shape\n",
        "    \n",
        "    xba_final = np.zeros((tot_rows, w_c))\n",
        "    j = 0\n",
        "\n",
        "    # print(\"Cells Xbar Output\\n\",all_cells)\n",
        "    for cells in all_cells: # Cells which are unaffected due to the faults\n",
        "        pos_cell = cells[0]\n",
        "        neg_cell = cells[1]\n",
        "        \n",
        "        j = int(xbar_cols(pos_cell[1]))\n",
        "        # print('pos_cell - Out: ', pos_cell)\n",
        "        # print('Position - Out: ', j)\n",
        "        # Use Positive Cell for Value feeds\n",
        "        xba_final[pos_cell[0], j] = xba[pos_cell[0], pos_cell[1]] - xba[pos_cell[0], pos_cell[1]+1]\n",
        "        # print('pos_cell - Out: ', pos_cell)\n",
        "        \n",
        "        # print('Step 1')\n",
        "        \n",
        "    if len(f_gp_cell) > 0:\n",
        "        # print(\"f_gp_cell: \",f_gp_cell)\n",
        "        for f_cells in f_gp_cell: # Cells which are unaffected due to the faults\n",
        "            pos_cell = f_cells[0]\n",
        "            neg_cell = f_cells[1]\n",
        "            rec_pos = f_cells[2]\n",
        "            rec_neg = f_cells[3]\n",
        "\n",
        "            j = int(xbar_cols(pos_cell[1]))\n",
        "\n",
        "            xba_final[pos_cell[0], j] = xba_final[pos_cell[0], j] + xba[rec_pos[0], rec_pos[1]] - xba[rec_pos[0], rec_pos[1]+1]\n",
        "            \n",
        "    # return xba_final[:w_r,:]\n",
        "    return xba_final[:w_r+1,:]\n",
        "\n",
        "\n",
        "# Define A function to pick up corresponding Columns to be written to\n",
        "def xbar_cols(column_number):\n",
        "    \n",
        "    if column_number%6==0:\n",
        "        \n",
        "        col = (column_number//6)*2\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        col = (column_number//6)*2 + 1\n",
        "    \n",
        "    return col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MuNXueiZwwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.datasets import mnist, cifar10, fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dropout, BatchNormalization, Dense, Conv2D, MaxPool2D, AveragePooling2D, Flatten,MaxPooling2D, Activation, GlobalMaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "from keras.utils import layer_utils, np_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4vqHg8HZ0Il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lenet5(weight_checker, weight_file, eval_tool, re_train=False):\n",
        "    tools = []\n",
        "    \n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    \n",
        "    # Convert the Targets to Categorical values\n",
        "    y_train_cat = to_categorical(y_train)\n",
        "    y_test_cat = to_categorical(y_test)\n",
        "    \n",
        "    # Reshape Training and Test Datasets\n",
        "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "    \n",
        "    # Build The Model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(6, kernel_size=(5, 5), input_shape=(28, 28, 1), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(16, kernel_size=(5, 5), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(120, kernel_size=(5, 5)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(84))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #####################################\n",
        "    #     MEMRISTOR WEIGHTS MODEL       #\n",
        "    #####################################\n",
        "    weights = np.load(weight_file)\n",
        "    model.set_weights(weights)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "    #####################################\n",
        "    #           MODEL SUMMARY           #\n",
        "    #####################################\n",
        "    # print(model.summary())\n",
        "    \n",
        "    # Test Model Accuracy\n",
        "    Accuracy = model.evaluate(X_test, y_test_cat)\n",
        "    Accuracy_retrained = Accuracy[1]\n",
        "    \n",
        "    print(f'Evaluation Tool: {eval_tool}')\n",
        "    \n",
        "    res_or = model.predict_classes(X_test[:6])\n",
        "    \n",
        "    tools.append(res_or)\n",
        "    \n",
        "    # Retrain Model Using the Wiehts as initializers    \n",
        "    if re_train == True:\n",
        "        model.fit(X_train, y_train_cat, batch_size=128, validation_split=0.2)\n",
        "        \n",
        "        x_weights = weight_checker['x_weights']\n",
        "        final_weight = weight_checker['weight']\n",
        "        weight_faultfree = weight_checker['weight_faultfree']\n",
        "        \n",
        "        retrained_weights = np.array(model.get_weights())\n",
        "        \n",
        "        for i in range(x_weights.shape[0]):\n",
        "            my_shape = x_weights[i].shape\n",
        "            if len(my_shape) == 1:\n",
        "                for j in range(x_weights[i].shape[0]):\n",
        "                    if x_weights[i][j] == False:\n",
        "                        retrained_weights[i][j] = final_weight[i][j]\n",
        "                        \n",
        "            elif len(my_shape) == 2:\n",
        "                for j in range(my_shape[0]):\n",
        "                    for k in range(my_shape[1]):                        \n",
        "                        if x_weights[i][j][k] == False:\n",
        "                            retrained_weights[i][j][k] = final_weight[i][j][k]\n",
        "                            \n",
        "        model.set_weights(retrained_weights)\n",
        "        model.compile(loss='categorical_crossentropy',optimizer='adadelta', metrics=['accuracy'])\n",
        "        Accuracy_retrained = model.evaluate(X_test, y_test_cat)\n",
        "        \n",
        "        res_retrained = model.predict_classes(X_test[:6])\n",
        "        \n",
        "        tools.append(res_retrained)\n",
        "    \n",
        "    # Visualize Results\n",
        "    \n",
        "#     for res in tools:\n",
        "#         plt.style.use('ggplot')\n",
        "#         plt.figure(figsize=(10, 10))\n",
        "\n",
        "#         for i in range(6):\n",
        "#             plt.subplot(1, 6, i+1)\n",
        "#             plt.imshow(X_test[i, :,:].reshape((28,28)), cmap='gray')\n",
        "#             plt.gca().get_xaxis().set_ticks([])\n",
        "#             plt.gca().get_yaxis().set_ticks([])\n",
        "#             plt.xlabel('Pred: %d' % res[i])\n",
        "#         plt.show()\n",
        "    \n",
        "    return Accuracy, Accuracy_retrained    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XaJZDyrvZ5C2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def FashionMnist(converted_weight, weight_file, eval_tool, re_train=False):\n",
        "    \n",
        "    tools = []\n",
        "    \n",
        "    # Check the operating System\n",
        "    import os\n",
        "    # surpress Tensorflow warning information\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "    # Number of classes\n",
        "    num_classes = 10\n",
        "\n",
        "    # Batch size and number of epochs\n",
        "    batch_size = 128\n",
        "    # epochs = 24\n",
        "\n",
        "    # Input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "\n",
        "    # Load the training and test data from keras\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Reshape the data as required by the backend\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    # Scale the pixel intensities\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # Change the y values to categorical values\n",
        "    y_train_cat = to_categorical(y_train, num_classes)\n",
        "    y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,\n",
        "    kernel_size=(3, 3),\n",
        "    activation='relu',\n",
        "    input_shape=input_shape))\n",
        "\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3),activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "#     # Compile the model\n",
        "#     model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "\n",
        "#     # Train the model\n",
        "#     hist = model.fit(x_train, y_train_cat,\n",
        "#     batch_size=batch_size,\n",
        "#     epochs=epochs,\n",
        "#     validation_data=(x_test, y_test_cat), \n",
        "#     verbose=2)\n",
        "\n",
        "#     # Evaluate the model on test data\n",
        "#     score = model.evaluate(x_test, y_test_cat, verbose=2)\n",
        "#     print('Test Loss: ', score[0])\n",
        "#     print('Test Accuracy: ', score[1])\n",
        "\n",
        "#     # Visualize the training progress\n",
        "#     epoch_list = list(range(1, len(hist.history['acc'])+1))\n",
        "#     plt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\n",
        "#     plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
        "#     plt.show()\n",
        "\n",
        "#     np.save('fashion_mnist_weight.npy', model.get_weights())\n",
        "\n",
        "    #####################################\n",
        "    #     MEMRISTOR WEIGHTS MODEL       #\n",
        "    #####################################\n",
        "    weights = np.load(weight_file)\n",
        "    model.set_weights(weights)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "    #####################################\n",
        "    #           MODEL SUMMARY           #\n",
        "    #####################################\n",
        "    # print(model.summary())\n",
        "    \n",
        "    # Test Model Accuracy\n",
        "    Accuracy = model.evaluate(x_test, y_test_cat)\n",
        "    \n",
        "    print(f'Evaluation Tool: {eval_tool}')\n",
        "    \n",
        "    res_or = model.predict_classes(x_test[:6])\n",
        "    \n",
        "    tools.append(res_or)\n",
        "    # Retrain Model Using the Wiehts as initializers\n",
        "    accuracy = Accuracy[1]\n",
        "    retrained = Accuracy[1]\n",
        "    \n",
        "    if re_train == True:\n",
        "        \n",
        "        model.fit(x_train, y_train_cat, batch_size=batch_size, validation_split=0.2)\n",
        "    \n",
        "        Accuracy_retrained = model.evaluate(x_test, y_test_cat)\n",
        "        \n",
        "        res_retrained = model.predict_classes(x_test[:6])\n",
        "        \n",
        "        tools.append(res_retrained)\n",
        "        \n",
        "        retrained = Accuracy_retrained[1]\n",
        "    \n",
        "    # Visualize Results\n",
        "    \n",
        "#     for res in tools:\n",
        "#         plt.style.use('ggplot')\n",
        "#         plt.figure(figsize=(10, 10))\n",
        "\n",
        "#         for i in range(6):\n",
        "#             plt.subplot(1, 6, i+1)\n",
        "#             plt.imshow(x_test[i, :,:].reshape((28,28)), cmap='gray')\n",
        "#             plt.gca().get_xaxis().set_ticks([])\n",
        "#             plt.gca().get_yaxis().set_ticks([])\n",
        "#             plt.xlabel('Pred: %d' % res[i].eval())\n",
        "#         plt.show()\n",
        "    \n",
        "    return accuracy, retrained  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UPCd4FHBZ-BJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_weight(cond_vals, num_bits, default_weight, perc_def, filter_size=4, model_used='normal', fix_used='none', case=\"crossbar\", seed_val=0):\n",
        "    \n",
        "    acc_or =[]\n",
        "    ideal_acc = []\n",
        "    w_b_split = []\n",
        "    \n",
        "    # Retrained\n",
        "    rt_acc_or =[]\n",
        "    \n",
        "    # filename = 'weights_MNIST_CNN_npy.npy'\n",
        "\n",
        "    or_weights = np.load(default_weight)\n",
        "\n",
        "    W = []\n",
        "    W_init = []\n",
        "    \n",
        "    # Get the weight shape of the original weight to help in looping\n",
        "    # Through the weights. This helps determine the trained layers\n",
        "\n",
        "    tot_weights = or_weights.shape[0]\n",
        "\n",
        "    # General Weight Reader For all Layers in any network\n",
        "    for w in range(0, tot_weights,2):\n",
        "        # Input Layer\n",
        "        # The Even indices correspond to the \n",
        "        l_weight = or_weights[w]\n",
        "        l_bias = or_weights[w+1]\n",
        "\n",
        "        # Shape of the Weight Section\n",
        "        l =  l_weight.shape\n",
        "\n",
        "        weight = l_weight.reshape(l)\n",
        "\n",
        "        dims = len(l)\n",
        "        weights = []\n",
        "        if dims > 2:\n",
        "            for i in range(l[0]):\n",
        "                for j in range(l[1]):\n",
        "                    if dims == 4:\n",
        "                        for k in range(l[2]):\n",
        "                            weights.append(weight[i,j,k])\n",
        "                    else:\n",
        "                        weights.append(weight[i,j])                \n",
        "        elif dims == 1:\n",
        "            weights = weight.reshape(1,l[0])\n",
        "        else:\n",
        "            weights = weight\n",
        "\n",
        "        weights = np.array(weights)\n",
        "\n",
        "        w_inp, w_dim = weights.shape\n",
        "        # print(\"weights Shape: {}\".format(weights.shape))\n",
        "        \n",
        "        biases = l_bias.reshape(1, l_bias.shape[0])\n",
        "        # print(\"biases Shape: {}\".format(biases.shape))\n",
        "\n",
        "        # Get the maximum value of the weights abd bias\n",
        "        # Combine the weight and bias by stacking\n",
        "        # w_b_c = np.concatenate((weights, biases), axis=1)\n",
        "        w_b_C_T = np.vstack((weights, biases))\n",
        "        wb_r, wb_c = w_b_C_T.shape\n",
        "\n",
        "        # Define the wieghts and biases from the split\n",
        "        # w_b_split, max_w_b = weight_split(weights, w_b_C_T)\n",
        "        \n",
        "        # if model_used == 'normal':\n",
        "        \n",
        "        # Weight Split for the normal crossbar\n",
        "        w_b_split_norm, max_w_b_norm = weight_split(w_inp, w_dim, w_b_C_T, mode='normal')\n",
        "        # Calculate the Conductance values of the weights and Biases\n",
        "        wb_cond_norm = weight_bias_cond(w_b_split_norm, cond_vals, max_w_b_norm)\n",
        "        \n",
        "        # elif model_used == 'proposed':\n",
        "        \n",
        "        # Weight Split for the proposed crossbar\n",
        "        w_b_split_prop, max_w_b_prop = weight_split(w_inp, w_dim, w_b_C_T, mode='proposed')\n",
        "    \n",
        "        # Calculate the Conductance values of the weights and Biases\n",
        "        wb_cond_prop = weight_bias_cond(w_b_split_prop, cond_vals, max_w_b_prop)\n",
        "\n",
        "        # Introduce redundancy\n",
        "        if model_used == 'normal':\n",
        "            my_weights = add_red_array(wb_cond_prop, perc_def, cond_vals, 'proposed', filter_size)\n",
        "            normal_dist = add_red_array(wb_cond_norm, perc_def, cond_vals, model_used, filter_size)\n",
        "            \n",
        "        elif model_used == 'proposed':\n",
        "            my_weights = add_red_array(wb_cond_prop, perc_def, cond_vals, model_used, filter_size)        \n",
        "            normal_dist = add_red_array(wb_cond_norm, perc_def, cond_vals, 'normal', filter_size)\n",
        "        \n",
        "        # print(\"Weight Shape after Redundancy: \", my_weights.shape)\n",
        "\n",
        "        #################################################################################################\n",
        "        #                              PROPOSED WEIGHT SPLIT PATTERN                                    #\n",
        "        #################################################################################################\n",
        "        # Finnd the shape of normal distributed Weight\n",
        "        # print(normal_dist)\n",
        "        # print(normal_dist.shape)\n",
        "        \n",
        "        # Faults introduced to the crossbar\n",
        "        defected_weight = add_defects(normal_dist,my_weights, perc_def, cond_vals, model_used, filter_size, case, seed_val)\n",
        "        \n",
        "        # print(\"Weights After Applying Defects\\n\",defected_weight)\n",
        "        # print(defected_weight)\n",
        "        new_xbar = defected_weight[\"xbar\"]\n",
        "        all_xbr_cells = defected_weight[\"all_cells\"]\n",
        "        f_cell = defected_weight[\"f_cells\"]\n",
        "        sa_0 = defected_weight[\"SA_0\"]\n",
        "        sa_1 = defected_weight[\"SA_1\"]\n",
        "        \n",
        "        # print(\"defected_weight\\n\", defected_weight)\n",
        "        \n",
        "        # Visualization\n",
        "        p_cells = ()\n",
        "        n_cells = ()\n",
        "\n",
        "        # TO DO!\n",
        "        # FAULT handling\n",
        "        # Regarding the affected Cells\n",
        "\n",
        "        # Considering the bit levels\n",
        "        global bits\n",
        "        global L_weights\n",
        "        \n",
        "        # Obtain the Weights when Cells have not been recovered\n",
        "        bits_init = bit_level_precision(cond_vals, normal_dist, num_bits, max_w_b_norm)\n",
        "        # print(\"bits Prop\\n{}\".format(type(bits[0])))\n",
        "        if model_used == 'normal':\n",
        "            L_weights_init = xbar_output(bits_init[0],w_inp, w_dim)\n",
        "        \n",
        "        elif model_used == 'proposed':\n",
        "            f_grp_mapping = []\n",
        "            L_weights_init = xbar_output_prop(bits_init[0],w_inp, w_dim, grouped_cells, f_grp_mapping)\n",
        "        \n",
        "        # Consider Each approach\n",
        "        if fix_used == 'none':            \n",
        "            bits = bit_level_precision(cond_vals, new_xbar, num_bits, max_w_b_norm)\n",
        "            # print(\"bits Prop\\n{}\".format(type(bits[0])))\n",
        "            L_weights = xbar_output(bits[0],w_inp, w_dim)\n",
        "            # print(\"L_weights Normal\\n{}\".format(L_weights))\n",
        "            \n",
        "        elif fix_used == 'existing_cells':\n",
        "            fault_tol = corr_rows_cols(my_weights, defected_weight, w_dim, cond_vals)\n",
        "            bits = bit_level_precision(cond_vals, fault_tol, num_bits, max_w_b_norm)\n",
        "            L_weights = xbar_output(bits[0], w_inp, w_dim)\n",
        "        \n",
        "        elif fix_used == 'redundant_cols':            \n",
        "            tol_red_col, red_col_map = red_rows_cols(my_weights, defected_weight, w_dim, cond_vals, seed_val)\n",
        "            bits = bit_level_precision(cond_vals, tol_red_col, num_bits, max_w_b_norm)\n",
        "            L_weights = xbar_output_red_col(bits[0],  w_inp, w_dim, red_col_map, defected_weight, all_xbr_cells)\n",
        "\n",
        "        # Fault Handled Weights Using Both Existing Cells and Redundant Rows and Columns\n",
        "        elif fix_used == 'combined':\n",
        "            combined_approach = combined(my_weights, defected_weight, w_dim, cond_vals, seed_val)\n",
        "            tol_mixed = combined_approach[\"f_xbr\"]\n",
        "            # faulty_both = combined_approach[\"both_faulty\"]\n",
        "            cell_mapping = combined_approach[\"mapping\"]\n",
        "            bits = bit_level_precision(cond_vals, tol_mixed, num_bits, max_w_b_norm)\n",
        "            L_weights = xbar_output_combined(bits[0],  w_inp, w_dim, cell_mapping, defected_weight, all_xbr_cells)\n",
        "            \n",
        "        elif fix_used == 'proposed':                        \n",
        "            # print(\"Original\\n{}\\nCalculated\\n{}\\nCeel Groups\\n{}\\nConductance\\n{}\\n\".format(my_weights, defected_weight, grouped_cells, cond_vals))\n",
        "            # Make the Cell Groupings\n",
        "            # print(\"my_weights Shape: \", my_weights.shape)\n",
        "            # print(\"Defected Cells: \", f_cell)\n",
        "            grouped_cells = groupings(all_xbr_cells, filter_size)\n",
        "            # print(\"grouped_cells: \", grouped_cells)\n",
        "            \n",
        "            # print(\"Grouped For Recovery Cells: \", f_grp)\n",
        "            cells_considered = recoverable(f_cell, filter_size)\n",
        "            tol_prop, f_grp_mapping = proposed_approach(my_weights, defected_weight, cells_considered, cond_vals)\n",
        "            \n",
        "            bits = bit_level_precision(cond_vals, tol_prop, num_bits, max_w_b_prop)\n",
        "            # print(\"bits Prop\\n{}\".format(type(bits[0])))\n",
        "            L_weights = xbar_output_prop(bits[0], w_inp, w_dim, grouped_cells, f_grp_mapping)\n",
        "            # print(\"L_weights Proposed\\n{}\".format(L_weights))\n",
        "            # print(\"defected_weight\\n{}\".format(defected_weight['xbar'].shape))\n",
        "        \n",
        "        w = L_weights[:w_inp, :].reshape((l_weight.shape))\n",
        "        b = L_weights[w_inp, :].reshape(l_bias.shape)\n",
        "        \n",
        "        w_init = L_weights_init[:w_inp, :].reshape((l_weight.shape))\n",
        "        b_init = L_weights_init[w_inp, :].reshape(l_bias.shape)\n",
        "        \n",
        "        # Weight for cells not recovered\n",
        "        W_init.append(w_init)\n",
        "        W_init.append(b_init)\n",
        "        \n",
        "        # Weight of Cells if at all recovered\n",
        "        W.append(w)\n",
        "        W.append(b)\n",
        "    \n",
        "    W = np.array(W)\n",
        "    W_init = np.array(W_init)\n",
        "    \n",
        "    converted={\n",
        "        'weight':W,\n",
        "        'weight_init':W_init,\n",
        "        'fix_tool':fix_used\n",
        "    }\n",
        "    \n",
        "    return converted\n",
        "\n",
        "def recoverable(faulty_cells, split):\n",
        "    recovery_cells = []\n",
        "    for gp_cell in faulty_cells:\n",
        "        \n",
        "        if gp_cell[1]%6 == 0:\n",
        "            recovery_cells.append([gp_cell, (gp_cell[0], gp_cell[1]+1), (gp_cell[0], gp_cell[1]+split), (gp_cell[0], gp_cell[1]+split+1)])\n",
        "            \n",
        "        elif gp_cell[1]%6 == 1:\n",
        "            recovery_cells.append([(gp_cell[0], gp_cell[1]-1),gp_cell,(gp_cell[0], gp_cell[1]+split-1), (gp_cell[0], gp_cell[1]+split)])\n",
        "            \n",
        "        elif gp_cell[1]%6 == 2:\n",
        "            recovery_cells.append([gp_cell, (gp_cell[0], gp_cell[1]+1), (gp_cell[0], gp_cell[1]), (gp_cell[0], gp_cell[1])])\n",
        "            \n",
        "        elif gp_cell[1]%6 == 3:\n",
        "            recovery_cells.append([(gp_cell[0], gp_cell[1]-1), gp_cell, (gp_cell[0], gp_cell[1]+1), (gp_cell[0], gp_cell[1]+2)])\n",
        "            \n",
        "        elif gp_cell[1]%6 == 4:\n",
        "            recovery_cells.append([(gp_cell[0], gp_cell[1]-2), (gp_cell[0], gp_cell[1]-1), gp_cell, (gp_cell[0], gp_cell[1]+1)])\n",
        "        \n",
        "        else:\n",
        "            recovery_cells.append([(gp_cell[0], gp_cell[1]-3), (gp_cell[0], gp_cell[1]-2), (gp_cell[0], gp_cell[1]-1),(gp_cell[0], gp_cell[1])])\n",
        "    return recovery_cells"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j4saUFH3aCRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy_check(converted_weight, perc_def, model, new_weight_filename='Memristor_weights.npy', re_train=False):\n",
        "    tool = converted_weight['fix_tool']\n",
        "    weight_init = converted_weight['weight_init']\n",
        "    final_weight = converted_weight['weight']\n",
        "    \n",
        "    weight_check = []\n",
        "    weight_checker = {}\n",
        "    \n",
        "    for i in range(weight_init.shape[0]):\n",
        "        weight_check.append(weight_init[i] == final_weight[i])\n",
        "        # print(weight_init[i].shape)\n",
        "    weight_checker['weight_faultfree'] = weight_init # Cross referenced Weights    \n",
        "    weight_checker['x_weights'] = np.array(weight_check) # Cross referenced Weights\n",
        "    weight_checker['weight'] = final_weight              # Final Weights after recovery\n",
        "    \n",
        "    # print(\"Final: {}, Shape: {}\".format(final_weight, final_weight.shape))\n",
        "    # print(\"Initial: {}, Shape: {}\".format(weight_init, weight_init.shape))\n",
        "    \n",
        "    # comp = np.all([weight_init, final_weight])\n",
        "    # print(comp)\n",
        "    \n",
        "    with open (new_weight_filename, 'r+'):\n",
        "        np.save(new_weight_filename, np.array(final_weight))\n",
        "    \n",
        "    #LeNET Model\n",
        "    accuracy_test, acc_retrained = model(weight_checker, new_weight_filename, tool, re_train)\n",
        "    \n",
        "    print(f'Defect percentage: {perc_def} --> Accuracy:-{tool}: {accuracy_test[1]}')\n",
        "    \n",
        "    if re_train == True:\n",
        "        print(f'Retrained Accuracy:-{tool}: {acc_retrained[1]}')\n",
        "    \n",
        "    print(f'{\"_\"*80}')\n",
        "    \n",
        "    return accuracy_test, acc_retrained\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaIctEjQcAce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tGxvG26dbuD-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Weight Configurations\n",
        "#@markdown Enter the information for weights\n",
        "\n",
        "weight_file_path = 'Memristor_Files/weights_LeNET_npy.npy'  #@param {type:\"string\"}\n",
        "percentage_defect = 0  #@param {type: \"slider\", min: 0, max: 10}\n",
        "bits = 4  #@param {type: \"integer\"}\n",
        "crossbar_cell_split = 4  #@param {type: \"integer\"}\n",
        "approach = \"normal\"  #@param ['normal', 'proposed', 'wednesday', 'thursday']\n",
        "recovery_method = \"None\" #@param [\"None\", \"Existing_cells\", \"Redundant_cols\", \"combined\", \"proposed\"]\n",
        "testing_criterion = \"crossbar_with_split\" #@param [\"crossbar_with_split\", \"crossbar_no_split\"]\n",
        "retrain = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbk5vJFicnIc",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "5a84f0ad-c958-4ce6-8f3c-7b92504e3efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "from google.colab import files, drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g4b3co_TqBCb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "drive_path = \"/content/drive/My Drive/\"\n",
        "file_path = drive_path + weight_file_path\n",
        "\n",
        "extra_path_index = 0\n",
        "start_index = weight_file_path.find('/')\n",
        "next_index = start_index\n",
        "while next_index != -1:\n",
        "\tnew_index = weight_file_path.find('/', next_index+1)\n",
        "\tif new_index == -1:\n",
        "\t\tbreak\n",
        "\telse:\n",
        "\t\tnext_index = new_index\n",
        "\n",
        "additional_path = weight_file_path[:next_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1k87ba1aJKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main(approach, bits, Ron, Roff, file_path, testing_criterion, retrain):\n",
        "    # Ron, Roff = (int(input('R-on: ')), int(input('R-off: ')))\n",
        "\n",
        "    # Get the Memristance values of the meristor\n",
        "    cond_vals = conductanceValues(Ron, Roff)\n",
        "\n",
        "    # Split of Conductance Values\n",
        "    MINcond = cond_vals['c_min']\n",
        "    MINcond = cond_vals['c_max']\n",
        "    condRANGE = cond_vals['c_range']\n",
        "\n",
        "    # Considering the bit levels\n",
        "    num_bits = bits\n",
        "\n",
        "    default_weights = file_path\n",
        "    # default_weights = 'fashion_mnist_weight.npy'\n",
        "    # default_weights = 'weights_alexnet_cifar10.npy'\n",
        "\n",
        "    # model = eval(input('Enter model (lenet5, FashionMnist, ..): '))\n",
        "\n",
        "    model = eval(input('Enter model (lenet5, Alexnet, ..): '))\n",
        "    converted_weights = np.array([])\n",
        "    software_based_accuracy = model(converted_weights, default_weights, 'Ideal')\n",
        "\n",
        "    print(f'Ideal/Software Based Accuracy: {software_based_accuracy[1]}\\n{\"+\"*40}')\n",
        "\n",
        "    # Define Approach to Use\n",
        "    approach = approach.lower()\n",
        "\n",
        "    # Define Fix Model to Use\n",
        "\n",
        "    filter_size=4\n",
        "    if approach != 'proposed':\n",
        "        fix_model = recovery_method\n",
        "\n",
        "    else:\n",
        "        fix_model = 'proposed'\n",
        "        filter_size = int(input(\"Enter the column size for the split: \"))\n",
        "    test_case = testing_criterion\n",
        "\n",
        "    # Introduce Fault Defects\n",
        "    # percentage_defect = int(input(\"Enter Fault Percentage: \"))\n",
        "    with open ('accuracy_tracker.txt', 'w+') as f:\n",
        "        f.write(\"perc_def\\tAccuracyies\\tAverage\\n\")\n",
        "        f.write(\"_\"*40+\"\\n\")\n",
        "\n",
        "    # seed_vals = [123, 111, 155, 555, 100,789, 329, 500, 907, 644]\n",
        "\n",
        "    seed_vals = [0, 123, 579, 111, 155, 555, 222, 100, 888, 456, 789, 329, 500, 579, 999, 234, 907, 644, 811, 440]\n",
        "\n",
        "\n",
        "\n",
        "    accs = []\n",
        "    acc_retrain= []\n",
        "    re_train = retrain\n",
        "\n",
        "    for my_seed in seed_vals:\n",
        "\n",
        "        converted_weights = convert_weight(cond_vals, num_bits, default_weights, percentage_defect, filter_size, approach, fix_model, test_case, seed_val=my_seed)\n",
        "\n",
        "        acc = accuracy_check(converted_weights, percentage_defect, model, new_weight_filename=file_path, re_train = re_train)\n",
        "\n",
        "        accs.append(acc[0][1])\n",
        "        acc_retrain.append(acc[1][1])\n",
        "\n",
        "    with open ('accuracy_tracker.txt', 'w+') as f:\n",
        "        f.write(\"{}\\t{}\\t{}\\n\".format(percentage_defect,accs, np.array(accs).mean()))\n",
        "        f.write(\"{}\\t{}\\t{}\\n\".format(percentage_defect,acc_retrain, np.array(acc_retrain).mean()))\n",
        "\n",
        "    #     sendMail('accuracy_tracker.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJ4f4Bx4sipV",
        "colab_type": "code",
        "outputId": "b809842f-7b4a-4869-fc15-c5867a8f88b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main(approach, bits, Ron, Roff, file_path, testing_criterion, retrain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter model (lenet5, Alexnet, ..): lenet5\n",
            "10000/10000 [==============================] - 6s 554us/step\n",
            "Evaluation Tool: Ideal\n",
            "Ideal/Software Based Accuracy: 0.9878\n",
            "++++++++++++++++++++++++++++++++++++++++\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-6e068b5bd444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapproach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-c106782ab413>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(approach, bits, Ron, Roff, file_path, testing_criterion, retrain)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmy_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mconverted_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage_defect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage_defect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_weight_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-4101fee18474>\u001b[0m in \u001b[0;36mconvert_weight\u001b[0;34m(cond_vals, num_bits, default_weight, perc_def, filter_size, model_used, fix_used, case, seed_val)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m# print(\"defected_weight\\n{}\".format(defected_weight['xbar'].shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'L_weights' is not defined"
          ]
        }
      ]
    }
  ]
}